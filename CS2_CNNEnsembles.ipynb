{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS2_CNNEnsembles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctFxOpvUnp1k",
        "outputId": "1ee69cea-234a-4b00-ddef-9681e7e1440f"
      },
      "source": [
        "!pip install tensorflow-io"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.19.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (22.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.7 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.19.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.19.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.6.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-io) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.15.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.36.2)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.34.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.3.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (2.5.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.32.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (57.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow-io) (3.5.0)\n",
            "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "Successfully installed tensorflow-io-0.19.1 tensorflow-io-gcs-filesystem-0.19.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi2tGfYon78K",
        "outputId": "41a127e1-9a76-407b-8eb4-3b647a655234"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 679 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oGDO0AaoGAe"
      },
      "source": [
        "# Importing the necessary libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uupgDDLoGTZh"
      },
      "source": [
        "# Global variables \n",
        "img_ht = 384\n",
        "img_wt = 768\n",
        "srate=48000\n",
        "class_n=24\n",
        "num_mels=384\n",
        "f_min=40\n",
        "f_max=24000\n",
        "batch_size=8\n",
        "num_steps=140"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJOW5jZhoInZ"
      },
      "source": [
        "train_tp=pd.read_csv('/content/drive/MyDrive/Appliedai files/Case_Study_2/train_tp.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKR5nBXZoKyn"
      },
      "source": [
        "#train_test_split\n",
        "X_train,X_cv=train_test_split(train_tp, stratify=train_tp['species_id'], test_size=0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJs0y9z1oMof"
      },
      "source": [
        "test=os.listdir('/content/drive/MyDrive/Appliedai files/Case_Study_2/test/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSUiuMSToOTl"
      },
      "source": [
        "X_train.reset_index(inplace=True)\n",
        "X_cv.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x623C7SVoZeJ"
      },
      "source": [
        "#https://www.tensorflow.org/io/tutorials/audio?hl=pt\n",
        "\n",
        "def create_mel_spectrogram(file):\n",
        "    \"\"\" This function reads the file and computes the mel spectrogram and returns the spectrogram\"\"\"\n",
        "    audio = tfio.IOTensor.graph(tf.int16).from_audio(file)\n",
        "    audio_slice = audio[100:]\n",
        "\n",
        "    # remove last dimension\n",
        "    audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
        "    audio_tensor = tf.cast(audio_tensor, tf.float32)\n",
        "\n",
        "    # Convert to spectrogram\n",
        "    spectrogram = tfio.audio.spectrogram(audio_tensor, nfft=2048, window=2048, stride=512)\n",
        "\n",
        "    # Convert to mel-spectrogram\n",
        "    mel_spectrogram = tfio.audio.melscale(spectrogram, rate=srate, mels=num_mels, fmin=f_min, fmax=f_max)\n",
        "\n",
        "    # Convert to db scale mel-spectrogram\n",
        "    mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80)\n",
        "\n",
        "    # Expanding the dimensions of spectrograms by 1 \n",
        "    image = tf.expand_dims(mel_spectrogram, axis= -1)\n",
        "    # Resizing the spectrogram\n",
        "    image = tf.image.resize(image, [img_ht,img_wt])\n",
        "    # Converting the spectrogram to rgb\n",
        "    image = tf.image.grayscale_to_rgb(image)\n",
        "\n",
        "    # Returning mel_spectrogram\n",
        "    return image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7vbgeeNod_y"
      },
      "source": [
        "#https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "\n",
        "def augmentation(spectrogram, label):\n",
        "    \"\"\"In this function we resize the image and perform data augumentations for train data\"\"\"\n",
        "\n",
        "    # Getting a random value and based on the random value computing the augmentation\n",
        "    a = np.random.uniform()\n",
        "    if a<0.25:\n",
        "        # Flipping the spectrogram up to down\n",
        "        spectrogram = tf.image.flip_up_down(spectrogram)\n",
        "    elif a<0.5:\n",
        "      spectrogram = tf.image.flip_left_right(spectrogram)\n",
        "    elif a<0.75:\n",
        "        # Adding a random contrast to spectrogram\n",
        "        spectrogram = tf.image.random_contrast(spectrogram, 0.2,0.5)\n",
        "    else:\n",
        "        # Adding a random brightness to spectrogram\n",
        "        spectrogram = tf.image.random_brightness(spectrogram,0.2)\n",
        "\n",
        "    # Returning the spectrogram image\n",
        "    return spectrogram, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdFIYXoAtdKD"
      },
      "source": [
        "def preprocess_train(file):\n",
        "    \"\"\"Preprocessing train files\"\"\"\n",
        "    \n",
        "    image = create_mel_spectrogram('/content/drive/MyDrive/Appliedai files/Case_Study_2/train/'+file['recording_id']+'.flac')\n",
        "    \n",
        "    # Computing the one hot encoded values of species_id\n",
        "    label = tf.one_hot(file['species_id'], class_n)\n",
        "    # Returning the spectrogram and one hot encoded species_id\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def preprocess_val(file):\n",
        "    \"\"\"Preprocessing validation files\"\"\"\n",
        "    image = create_mel_spectrogram('/content/drive/MyDrive/Appliedai files/Case_Study_2/train/'+file['recording_id']+'.flac')\n",
        "\n",
        "    # Computing the one hot encoded values of species_id\n",
        "    label = tf.one_hot(file['species_id'], class_n)\n",
        "    # Returning the spectrogram and one hot encoded species_id\n",
        "    return image, label\n",
        "\n",
        "    \n",
        "def preprocess_test(file):\n",
        "    \"\"\"Preprocessing test files\"\"\"\n",
        "    image = create_mel_spectrogram('/content/drive/MyDrive/Appliedai files/Case_Study_2/test/'+file)\n",
        "\n",
        "    file_name = tf.strings.split(file,'.')[0]\n",
        "    # Returning only the spectrogram image for test dataset \n",
        "    return image, file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z11jYHTGtwEP"
      },
      "source": [
        "# Creating a dataset from train data and mapping the preprocess train function \n",
        "files_ds = tf.data.Dataset.from_tensor_slices(dict(X_train))\n",
        "train_dataset = files_ds.map(preprocess_train).cache().map(augmentation).shuffle(3).batch(batch_size).prefetch(-1).repeat()\n",
        "\n",
        "# Creating a dataset from train data and mapping the preprocess train function \n",
        "files_ds = tf.data.Dataset.from_tensor_slices(dict(X_cv))\n",
        "val_dataset = files_ds.map(preprocess_val).cache().shuffle(3).batch(batch_size).prefetch(-1)\n",
        "\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(test)\n",
        "test_dataset = files_ds.map(preprocess_test).cache().shuffle(3).prefetch(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-p6ez36t5ij"
      },
      "source": [
        "def lwlrap(y_true,y_score):\n",
        "  return tf.py_function(label_ranking_average_precision_score, (y_true,y_score), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7exgbJ2t_xk",
        "outputId": "e1055632-e44a-4c62-aa74-9084fbeac129"
      },
      "source": [
        "backbone = tf.keras.applications.EfficientNetB2(include_top = False,input_shape = (img_ht,img_wt,3), weights=\"imagenet\")\n",
        "for layer in backbone.layers[:0]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_1 = tf.keras.Sequential([\n",
        "            backbone,\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "            tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal()),\n",
        "            tf.keras.layers.Dropout(0.4),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Dense(class_n,bias_initializer=tf.keras.initializers.Constant(-2.))])\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "model_1.compile(optimizer=tfa.optimizers.RectifiedAdam(learning_rate=2e-3,total_steps=65*140,warmup_proportion=0.3,min_lr=1e-6), loss=tfa.losses.SigmoidFocalCrossEntropy(from_logits = True), metrics=[lwlrap])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
            "31793152/31790344 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnetb2 (Functional)  (None, 12, 24, 1408)      7768569   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1408)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               360704    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 24)                6168      \n",
            "=================================================================\n",
            "Total params: 8,136,465\n",
            "Trainable params: 8,068,378\n",
            "Non-trainable params: 68,087\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k859rL1MuGeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2647de19-5d3d-49e7-953e-13098e796696"
      },
      "source": [
        "#loading tensorboard\n",
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/\n",
        "from datetime import datetime\n",
        "#creating log directory\n",
        "logdir=\"logs/scalars_1/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard callback\n",
        "tensorboard_1 = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#lr_decay=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_lwlrap',factor=0.1, patience=5, mode='max')\n",
        "earlystop=tf.keras.callbacks.EarlyStopping(monitor='val_lwlrap',patience=15,mode='max')\n",
        "\n",
        "#Path for saving model\n",
        "filepath=\"/content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-{epoch:02d}-{val_lwlrap:.4f}.hdf5\"\n",
        "#Model checkpoint callback\n",
        "checkpoint_1 = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_lwlrap', save_best_only=True, verbose=1, mode='max', save_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CawlNiU7uN_p",
        "outputId": "5b9f924a-3474-47bf-8a9f-5e7fc3850b3c"
      },
      "source": [
        "model_fit_1=model_1.fit(train_dataset,steps_per_epoch=num_steps,validation_data=val_dataset,epochs=65,callbacks=[earlystop,tensorboard_1,checkpoint_1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "140/140 [==============================] - 157s 699ms/step - loss: 0.9282 - lwlrap: 0.1581 - val_loss: 0.6058 - val_lwlrap: 0.1567\n",
            "\n",
            "Epoch 00001: val_lwlrap improved from -inf to 0.15669, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-01-0.1567.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/65\n",
            "140/140 [==============================] - 90s 640ms/step - loss: 0.7609 - lwlrap: 0.2008 - val_loss: 0.5692 - val_lwlrap: 0.1498\n",
            "\n",
            "Epoch 00002: val_lwlrap did not improve from 0.15669\n",
            "Epoch 3/65\n",
            "140/140 [==============================] - 90s 642ms/step - loss: 0.5901 - lwlrap: 0.2292 - val_loss: 0.6058 - val_lwlrap: 0.1783\n",
            "\n",
            "Epoch 00003: val_lwlrap improved from 0.15669 to 0.17829, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-03-0.1783.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/65\n",
            "140/140 [==============================] - 91s 647ms/step - loss: 0.4683 - lwlrap: 0.2895 - val_loss: 0.6219 - val_lwlrap: 0.2096\n",
            "\n",
            "Epoch 00004: val_lwlrap improved from 0.17829 to 0.20958, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-04-0.2096.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/65\n",
            "140/140 [==============================] - 90s 642ms/step - loss: 0.4212 - lwlrap: 0.3169 - val_loss: 1.0833 - val_lwlrap: 0.2523\n",
            "\n",
            "Epoch 00005: val_lwlrap improved from 0.20958 to 0.25235, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-05-0.2523.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.3768 - lwlrap: 0.3868 - val_loss: 0.6379 - val_lwlrap: 0.3623\n",
            "\n",
            "Epoch 00006: val_lwlrap improved from 0.25235 to 0.36232, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-06-0.3623.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/65\n",
            "140/140 [==============================] - 90s 642ms/step - loss: 0.3688 - lwlrap: 0.4043 - val_loss: 0.6843 - val_lwlrap: 0.3487\n",
            "\n",
            "Epoch 00007: val_lwlrap did not improve from 0.36232\n",
            "Epoch 8/65\n",
            "140/140 [==============================] - 90s 646ms/step - loss: 0.3498 - lwlrap: 0.4269 - val_loss: 0.5193 - val_lwlrap: 0.3769\n",
            "\n",
            "Epoch 00008: val_lwlrap improved from 0.36232 to 0.37691, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-08-0.3769.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.3361 - lwlrap: 0.4735 - val_loss: 0.5355 - val_lwlrap: 0.4788\n",
            "\n",
            "Epoch 00009: val_lwlrap improved from 0.37691 to 0.47882, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-09-0.4788.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3265 - lwlrap: 0.5078 - val_loss: 1.2286 - val_lwlrap: 0.2922\n",
            "\n",
            "Epoch 00010: val_lwlrap did not improve from 0.47882\n",
            "Epoch 11/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3304 - lwlrap: 0.4931 - val_loss: 0.6200 - val_lwlrap: 0.3690\n",
            "\n",
            "Epoch 00011: val_lwlrap did not improve from 0.47882\n",
            "Epoch 12/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3004 - lwlrap: 0.5426 - val_loss: 1.0183 - val_lwlrap: 0.5494\n",
            "\n",
            "Epoch 00012: val_lwlrap improved from 0.47882 to 0.54944, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-12-0.5494.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.2895 - lwlrap: 0.5726 - val_loss: 1.8834 - val_lwlrap: 0.3867\n",
            "\n",
            "Epoch 00013: val_lwlrap did not improve from 0.54944\n",
            "Epoch 14/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3078 - lwlrap: 0.5350 - val_loss: 1.3531 - val_lwlrap: 0.4004\n",
            "\n",
            "Epoch 00014: val_lwlrap did not improve from 0.54944\n",
            "Epoch 15/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3417 - lwlrap: 0.4904 - val_loss: 2.6133 - val_lwlrap: 0.2859\n",
            "\n",
            "Epoch 00015: val_lwlrap did not improve from 0.54944\n",
            "Epoch 16/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3810 - lwlrap: 0.4000 - val_loss: 1.4375 - val_lwlrap: 0.2439\n",
            "\n",
            "Epoch 00016: val_lwlrap did not improve from 0.54944\n",
            "Epoch 17/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3357 - lwlrap: 0.4565 - val_loss: 1.0915 - val_lwlrap: 0.4180\n",
            "\n",
            "Epoch 00017: val_lwlrap did not improve from 0.54944\n",
            "Epoch 18/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.3255 - lwlrap: 0.4927 - val_loss: 0.4756 - val_lwlrap: 0.4164\n",
            "\n",
            "Epoch 00018: val_lwlrap did not improve from 0.54944\n",
            "Epoch 19/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.3094 - lwlrap: 0.5122 - val_loss: 2.8358 - val_lwlrap: 0.3517\n",
            "\n",
            "Epoch 00019: val_lwlrap did not improve from 0.54944\n",
            "Epoch 20/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.2881 - lwlrap: 0.5654 - val_loss: 0.4640 - val_lwlrap: 0.4967\n",
            "\n",
            "Epoch 00020: val_lwlrap did not improve from 0.54944\n",
            "Epoch 21/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.2667 - lwlrap: 0.6091 - val_loss: 0.5131 - val_lwlrap: 0.5480\n",
            "\n",
            "Epoch 00021: val_lwlrap did not improve from 0.54944\n",
            "Epoch 22/65\n",
            "140/140 [==============================] - 91s 647ms/step - loss: 0.2774 - lwlrap: 0.5918 - val_loss: 0.4987 - val_lwlrap: 0.4534\n",
            "\n",
            "Epoch 00022: val_lwlrap did not improve from 0.54944\n",
            "Epoch 23/65\n",
            "140/140 [==============================] - 90s 646ms/step - loss: 0.2722 - lwlrap: 0.6054 - val_loss: 0.7985 - val_lwlrap: 0.4928\n",
            "\n",
            "Epoch 00023: val_lwlrap did not improve from 0.54944\n",
            "Epoch 24/65\n",
            "140/140 [==============================] - 90s 646ms/step - loss: 0.2593 - lwlrap: 0.6248 - val_loss: 0.4348 - val_lwlrap: 0.5502\n",
            "\n",
            "Epoch 00024: val_lwlrap improved from 0.54944 to 0.55016, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-24-0.5502.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/65\n",
            "140/140 [==============================] - 90s 641ms/step - loss: 0.2299 - lwlrap: 0.6873 - val_loss: 0.3729 - val_lwlrap: 0.5790\n",
            "\n",
            "Epoch 00025: val_lwlrap improved from 0.55016 to 0.57896, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-25-0.5790.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.2132 - lwlrap: 0.7209 - val_loss: 0.4276 - val_lwlrap: 0.6329\n",
            "\n",
            "Epoch 00026: val_lwlrap improved from 0.57896 to 0.63293, saving model to /content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-26-0.6329.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.2337 - lwlrap: 0.6750 - val_loss: 0.4206 - val_lwlrap: 0.5336\n",
            "\n",
            "Epoch 00027: val_lwlrap did not improve from 0.63293\n",
            "Epoch 28/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.2179 - lwlrap: 0.7073 - val_loss: 0.3111 - val_lwlrap: 0.5954\n",
            "\n",
            "Epoch 00028: val_lwlrap did not improve from 0.63293\n",
            "Epoch 29/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.2089 - lwlrap: 0.7335 - val_loss: 0.6078 - val_lwlrap: 0.5167\n",
            "\n",
            "Epoch 00029: val_lwlrap did not improve from 0.63293\n",
            "Epoch 30/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.2119 - lwlrap: 0.7266 - val_loss: 0.5160 - val_lwlrap: 0.6064\n",
            "\n",
            "Epoch 00030: val_lwlrap did not improve from 0.63293\n",
            "Epoch 31/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.2131 - lwlrap: 0.7278 - val_loss: 1.2543 - val_lwlrap: 0.5040\n",
            "\n",
            "Epoch 00031: val_lwlrap did not improve from 0.63293\n",
            "Epoch 32/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.2089 - lwlrap: 0.7243 - val_loss: 0.3726 - val_lwlrap: 0.5839\n",
            "\n",
            "Epoch 00032: val_lwlrap did not improve from 0.63293\n",
            "Epoch 33/65\n",
            "140/140 [==============================] - 90s 645ms/step - loss: 0.1964 - lwlrap: 0.7407 - val_loss: 0.5649 - val_lwlrap: 0.6246\n",
            "\n",
            "Epoch 00033: val_lwlrap did not improve from 0.63293\n",
            "Epoch 34/65\n",
            "140/140 [==============================] - 90s 644ms/step - loss: 0.1994 - lwlrap: 0.7519 - val_loss: 0.6565 - val_lwlrap: 0.6040\n",
            "\n",
            "Epoch 00034: val_lwlrap did not improve from 0.63293\n",
            "Epoch 35/65\n",
            "140/140 [==============================] - 90s 642ms/step - loss: 0.1828 - lwlrap: 0.7775 - val_loss: 0.5036 - val_lwlrap: 0.5625\n",
            "\n",
            "Epoch 00035: val_lwlrap did not improve from 0.63293\n",
            "Epoch 36/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.1901 - lwlrap: 0.7664 - val_loss: 0.5396 - val_lwlrap: 0.6257\n",
            "\n",
            "Epoch 00036: val_lwlrap did not improve from 0.63293\n",
            "Epoch 37/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.1855 - lwlrap: 0.7736 - val_loss: 0.5063 - val_lwlrap: 0.6092\n",
            "\n",
            "Epoch 00037: val_lwlrap did not improve from 0.63293\n",
            "Epoch 38/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.1702 - lwlrap: 0.8049 - val_loss: 2.7564 - val_lwlrap: 0.4507\n",
            "\n",
            "Epoch 00038: val_lwlrap did not improve from 0.63293\n",
            "Epoch 39/65\n",
            "140/140 [==============================] - 90s 642ms/step - loss: 0.2191 - lwlrap: 0.7243 - val_loss: 0.6227 - val_lwlrap: 0.5629\n",
            "\n",
            "Epoch 00039: val_lwlrap did not improve from 0.63293\n",
            "Epoch 40/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.1906 - lwlrap: 0.7621 - val_loss: 0.9064 - val_lwlrap: 0.4757\n",
            "\n",
            "Epoch 00040: val_lwlrap did not improve from 0.63293\n",
            "Epoch 41/65\n",
            "140/140 [==============================] - 90s 643ms/step - loss: 0.2269 - lwlrap: 0.7052 - val_loss: 0.4394 - val_lwlrap: 0.6224\n",
            "\n",
            "Epoch 00041: val_lwlrap did not improve from 0.63293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TknmPHwfPkim"
      },
      "source": [
        "%tensorboard --logdir /content/logs/scalars_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "gRONxC5BpD82",
        "outputId": "185fcf18-8796-44ed-8c2b-26f39b909432"
      },
      "source": [
        "#Loss and metric plots\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(filename='/content/drive/MyDrive/EffnetB2_loss.JPG')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFyY2hpc21hbiBEYXMAAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzM3AACSkgACAAAAAzM3AADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjA3OjMxIDE4OjI1OjI3ADIwMjE6MDc6MzEgMTg6MjU6MjcAAABBAHIAYwBoAGkAcwBtAGEAbgAgAEQAYQBzAAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjEtMDctMzFUMTg6MjU6MjcuMzczPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPkFyY2hpc21hbiBEYXM8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA+QFnAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKy/E8t/D4V1OTSAxvktZDBsGTv2nGB3NAGpRXlIuYh4e1ifTNat5IBYL58dlfzTuj7x87M3KPjcCOGP4VbubqBJNYHg/UZ7nThawm8ktrp7gQuZcOUbcSJPK3Egc8KetAHpdVr2/h09YDcbv386QJtGfmY4H4V59Pe26x6oPB2ozXOjrbQG5mtbl51iYygSGN8khvK3EhTkYB6mpruHQb6GGDQNTuLqyk1K0En2e8eSJG3HOyUEkMRjcA3ocAnkA9EqodSgXWU0w7vtDwG4HHG0MFPPrkisXwon2TVPEGnwvIba1vUECSSM/lhoY2IBYk4ySce9Z/il72PxJdPpe/wC2LoFwYfLGW3eYuMDufSgDtaK86trnTftUyeFNZuHszpUxv54JpLswS/L5bkZJEvL5UYY456Cq2m3lpJpWt29lqyxRpaxF9Q0++lu7dSWILMPvxOf4gGOF5yMZoA9OorkfAl3bXH9pR2UkcsMciYe1v2u7Ukr/AMs3YZU/3l5AJHPJrrqACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKbLKkMTyzOscaKWZ3OAoHUk9hTqyfFNidS8J6paJG0ry2sgREYgs204Ax74oAt6jYW+r6XLZzM3k3CjLRkZIyDkH8Kt4x0rzbWWv1tbSPR7fUYDFZwNbn7JdyM5DZZeCFiYY58wEsDjGODZnaSHxDaLdf2mNQk1s5fE4gaAh9ig/6sjaF+XrkE4zk0AegYx0oAx04rmvESXb+D0GhNdIPMiL+ZHNJN5O8b/lyJCcZ4BDEZxXPx/6O2mrq9xqV1aSSXTrHb2d3CyjCYXytzSlQSxGeBnjAAoA7fU9E0rW4449Z0yz1BIzuRbu3SUIfUBgcVJp+mafo9n9m0qxtrG3BLeTbQrGgJ6naoAzXDGPUUsIxrEesOzacFsBbiZnSbc/+sKdH2+V8z8fe561fskuRqxTWo9VfVPtEbRSWqyeR5flrkbv9WFzv3KfmJ6DO2gDrrO6gvrOK6tH3wzKHRsEbge+DzQ91BDdw2rvtmnDNGu0/MFxu56dxXGaHB/wjp0W4u3nsrQ6bJ9ue7mcRpJuj2Bt5wp5YAcdwKuaxeNrM0Vz4Uu4b2WK0u0Se1kWRY5SqbQWGQCe2aAOtAwMDiiuAljmkt7r+yhrVvYC3hEpmt7h384SZJCMVkcbeH2HnPGTmmXP2t9Es3eHU4o1luMRi3upVlB+78qkTRZ527gwXn/ZoA9CoqtpplbSrU3EckUphQukr7mU4GQT3PvVmgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACqS6Ppy6h9uWyhF1uLebsGQxGC31I4z1xV2igAqN7eJ7iOd41MsQIRyOVBxnH1wKkooAKKgnnkh2HYrB5Ag+bHU9elS5k/ur/wB9f/WoAdRTcyf3V/76/wDrUZk/ur/31/8AWoAdRVG31B7jUry08lVNrsy3mfe3DPTHFXMyf3V/76/+tQA6im5k/ur/AN9f/WprvIkbNsU7QTjd/wDWoAkoqNHkeNW2KNwBxu/+tTsyf3V/76/+tQA6im5k/ur/AN9f/WqNpZFmjTYp35539MfhQBNRUEk8kc0SeWp8wkZ39P0rN8T683hvw/cao1qLgQgfuxLtzk464NVGEpNRW7IlOMIuUtkbNFQwSyy28chjRS6hiA5OMj1xVc6hL5d4Vt1ZrUHC+Z9/Az6cUrO9irq1y9RWDp/iY3/gkeIVtAqm2ecwebnG3OV3bfbrio5PFMieAx4l+wKf9FFz9m8/se27b6e1aexne1utvmZe3p2vfpf5HRUVSt9Qa50mC+SJQs0SShd54DAH096t5k/ur/31/wDWrNqzszVNNXQ6im5k/ur/AN9f/WozJ/dX/vr/AOtSGOoqHzZPtHlbF+7uzv8Af6VJmT+6v/fX/wBagB1FNzJ/dX/vr/61GZP7q/8AfX/1qAHUVDDLJNCr7FGe2/8A+tUmZP7q/wDfX/1qAHUU3Mn91f8Avr/61RyyyR7PkU7mC/f6fpQBNRUE08kPl/u1O9wn3+mfwrnPCfjX/hKo7ho7EWxhuTDgzbsgDIb7o6+laRpzlFyS0RnKrCM1BvV7HVUU3Mn91f8Avr/61RrLI00ibFGzHO/rn8KzNCaim5k/ur/31/8AWozJ/dX/AL6/+tQA6io2eRULbFOBn73/ANapKACiiigAooooAKKKKACiiigCrffdg/67p/OrVUL+2U+Ud8vzTp/y0bjn61Y+yJ/z0m/7+t/jQBPRUH2RP+ek3/f1v8aPsif89Jv+/rf40AZ2m/8AIza1/wBsP/QDWxWFp1up8Sawu+X5fI5EjZ+4fetb7In/AD0m/wC/rf40AT0yf/j3k/3T/Ko/sif89Jv+/rf40ya1T7PJ+8m+6f8Alq3p9aAJ4P8Aj3j/AN0fyp9VYbVPs8f7yb7o/wCWren1p/2RP+ek3/f1v8aAJ6gl/wCPuD/gX8qPsif89Jv+/rf41DLap9rg/eTfxf8ALVvT60AST839sPTeT+Vcx8UVEvgOe373E8Ea+uTIv+Fbl6kVtOJ5Xn2QwvI2JWzgDJ71ymk6VfeOWt9Z1yWS30cOJrLTY5ixfB+V5G/oP/19dBcslVe0f6scWIfNGVGKu5X+7uzv+lZ9oMaldKej5OPxxVn7In/PSb/v63+NZ8Vqq6jnzJvmZ1/1rdufWuZHXI43Q5fs3wR1a2Od1nFe2/HUHL//ABVbM1tu+DKW2Bk6Mi8DPPlDn865e4As/Bfjy23yDydRlKgOcbZCuBjv3ruv7NU+DY7ctIP9DSPb5rYHygV6NZ2fN3lf8E/1PKoLmXL2hb8Wv0GeGZvtHw80h85/0KFSc55CgH+VdDXE+AlW5+GGmSmSXOxl4kIHyyMvT8K6/wCyJ/z0m/7+t/jXFXXLVkvNnoYeXNRg/JfkT0VB9kT/AJ6Tf9/W/wAaPsif89Jv+/rf41ibh/zEP+2X9anql9lT7f8A6yb/AFX/AD1b1+tTfZE/56Tf9/W/xoAnoqD7In/PSb/v63+NH2RP+ek3/f1v8aACz/49E/H+dT1Ss7VPsifvJu//AC1b1+tTfZE/56Tf9/W/xoAnqC5/5Y/9dVo+yJ/z0m/7+t/jUNzap+5/eTf61f8Alq3+NAD744EBPA85f615N8HZZEvryOY83QjuV4x/FIp/pXpetQpDYGQvMQoZiPNbsp96838FWotNf8MszsFvdHZflcjLLMzfyNelh/8Ad6i7/pdnk4r/AHqm+1/xsj2CoIv+Puf/AID/ACo+yJ/z0m/7+t/jUMVqn2uf95N/D/y1b0+teaesXaKg+yJ/z0m/7+t/jR9kT/npN/39b/GgCWX/AFL/AO6adVaW1TyX/eTfdP8Ay1b/ABqzQAUUUUAFFFFABVHWJbq30ueezkjjeFGc+ZGXyACcDkYPvz9KvVFdW6XdpLbyFgkqFGK9QCMcUAJcCd7bFqyJIxX5nGcDPJx64zj3qvpkssqTiSUzxxylIpioBkGBknGAcNkZAHSpLyya7t5YRdzwLImzMJUFeeSCQeSOP/r806ytDZwiL7RJMoACh1QbAOwCqBigCC/u7ceUpnjBWdNw3DjmrH221/5+I/8AvsUy++7B/wBd0/nVqgCD7ba/8/Ef/fYo+22v/PxH/wB9ip6KAMLTrq3HiTWGM0YVvIwdw5+Q1rfbbX/n4j/77FZ2m/8AIza1/wBsP/QDWxQBB9ttf+fiP/vsUya9tvs8n+kR/dP8Q9KtUyf/AI95P90/yoAghvbb7PH/AKRH90fxD0p/221/5+I/++xUkH/HvH/uj+VPoAp3OpW8Fu0izRMVxxvHrTXvrZrm3P2iPo38Q9KfqZxYt7kfzpVO57M+qE/+O1VvduTf3rGD4v1K3h0DVnSeMsNNmC/MOpBA/U1c8LSW9p4Q0iBp41aOyiDAt0OwZ/Wsf4lzGPwfquzl5IY4lHrulUY/LNdhbwi3tooV+7GgQcegxW8tKC83+SX+ZzQ1xMvJL8W/8hn221/5+I/++xVA3lss6P58fFww+8O4rWrPm4t5H/uXG79awjudMtjy7xdcxwN48tYpFJu/sEkIBHzElQ9enz3VqulFEnjAVAAN446V5j8TD5Hjj7N/DqdpbDH99luOn5DOa9Yu/wDkHyf7td+I/h033/yiv0PMwv8AFqrt/nJ/qcX4DuoLfwrqFg8yKbLUp4ACw5G8Nn/x6u1+22v/AD8R/wDfYrjvDv8AovifxbYdB51vdL7+YmT+oruK5sT/ABW+9n96udeE/gpdrr7nYg+22v8Az8R/99ij7ba/8/Ef/fYqeiuc6il9ttvt/wDx8R/6r+8PWpvttr/z8R/99ij/AJiH/bL+tT0AQfbbX/n4j/77FI19bBSftEfA/vCrFMmOLeQ+in+VAGZol7bDSYgZ4xgt/EP7xq/9ttf+fiP/AL7FVNBP/EqT/eb+daVVL4mTD4UQfbbX/n4j/wC+xUNze237n/SI/wDWr/EKu1Bc/wDLH/rqtSUY3im/gXw/dNHcR7lglYHcOMIa4u0eGzj+HN0rqoRGhk56eZGMZ/HJrsfHb+X4P1IkZ/0OcfnGR/Wuc8QL9i+HfhC7OCdPuLCQt7BAD+HNelh/gS7tr8Gv1PKxX8ST7JP8U/0O/wDttr/z8R/99ioYr22+1z/6RH/D/EPSrtQRf8fc/wDwH+VeaeqH221/5+I/++xR9ttf+fiP/vsVPRQBWlvbbyX/ANIj+6f4xVmmy/6l/wDdNOoAKKKKACiiigAooooAKKZNMsELSuHKqMkIhdvwABJ/Cm2tzHeWqXEO7Y4yNy4P5UAVb+Sb90BASBOmDvHPNWPOn/59j/32KZffdg/67p/OrVAEHnT/APPsf++xR50//Psf++xU9FAGFp0kw8SawRAST5GRvHHyGtbzp/8An2P/AH2KztN/5GbWv+2H/oBrYoAg86f/AJ9j/wB9io5Z5mglxb5wpBxIOOKt1nWr7o736k/nmmlpcTdmkTwyz/Z4/wDRj90fxj0p/nT/APPsf++xUkH/AB7x/wC6P5U+kMzNTlna2Vfs5G5wPvikhmnIs/8ARz90/wAY9KtXg3SW6+smahtDlLP/AIGKv7JmvjOS+IEks8dhaNDt+16pawYLA5yxOP0rtvOn/wCfY/8AfYrjvFP7/wAc+G7TP3r/AM4D/rnHn+tdxW1bSnBer/r7jCjrVqPzS/X9SDzp/wDn2P8A32KpO8zWd0Psx++x++K1KqqM290PVn/lXOtzqex5l8SoJJ/FnhG4aEjzZghw2cgOh/D7xr0m6kn+wyA2xHyf3xWRrugQ6zb6TeyytG+myCZAoHzngYP5Ct+7/wCPOX/cNdVSopU6ce1/zOOlScKlSb+1b8jh5JZbT4nP+5IF/o6Nt3jl0kA/9Brt/On/AOfY/wDfYrjfFI+zeMPCd6OFk861kPruQFR+YNdzUV9VCXl+TaLw+jnHs/zSf6kHnT/8+x/77FHnT/8APsf++xU9Fc51FLzZ/t//AB7H/Vf3x61N50//AD7H/vsUf8xD/tl/Wp6AIPOn/wCfY/8AfYqK6mnFpL/ox+4f4x6VcqC+OLGX6U1uKWxm6FLONNwLcnDn+MVpedP/AM+x/wC+xVXRuLaRfR60actxQ+Eg86f/AJ9j/wB9iobmWf8Adf6Mf9av8Yq7UFz/AMsf+uq1JRyvxFuJl8GX+6LywYHBYuO/H9ag8Vadd6j8MF0+2tGEgt4jGu4ZygBAHvxipPitJ5fgO9OM5Cr+bqP611FxH5Vpbx5zsdFz64rthJwpwkv5n+Fjz5wVSrUg/wCVL77lPQNd/t3QbTUrWHek8YJ+ccN0YfgcircUs/2uf/Rj/D/GPSuY0sHwr4+uNIPGm63uu7P0jnH+sj/Ec/kK62L/AI+5/wDgP8qwrQUZXjs9V/XlsdNCbnC0t1o/X/g7h50//Psf++xR50//AD7H/vsVPRWJuVpZp/Jf/Rj90/xirNNl/wBS/wDumnUAFFFFABRRRQAUUUUAFVNLgkt9NiimXa65yM57k1booAoX8Up8oi4YAzpgbV45+lWPJm/5+n/74X/CmX33YP8Arun86tZoAg8mb/n6f/vhf8KPJm/5+n/74X/Cp80ZoAwtOilPiTWALhgR5GTtHPyH2rW8mb/n6f8A74X/AArH0+7jXxrq9o3EjpC6+4C4P/oQrfzUxkpbFyhKFubrqQGGYDP2p/8Avhf8KyrKGYRzf6S43xFvur7+1bMzbbeQ+ik/pWfGNmz/AGrU/wCNax+FmEviRZhhm+zx/wClP90fwL6fSn+TN/z9P/3wv+FPgP8Ao8f+6P5VJmoNDPuIZTeWy/aX6sfur2H0qG1hl3wr9pf5XkH3V/wq5Kc6jAPRWNQ25xd7fSaT+Qq/smf2jkruOS5+LWkx+exa1t7mbdtHy5AT0rtvJm/5+n/74X/CuO0r/Sfi5eTdoNKCfi027P5Cu4zW2I05V2S/z/UwwuvPLvJ/ov0IPJm/5+n/AO+F/wAKrwQTMk4+0vzIw+6v+FX81BbH/Xf9dWrmOszjFK2ir/pLYOB91f730q5cwS/ZJc3L/cP8K+n0qDONJ2/3ZMf+PVeuT/ok3+438q0e/wAzKO3yOJ8fxSQ+HtI1Bp2b7HqFvKTtHAPynt712nkzf8/T/wDfC/4Vz/jax/tH4b6hAOWFqsigdcphh/6DWvoOojVvDun34IJuLdJG9mKjI/PNaz1op9m1+X/BMqfu15Luk/zT/Qs+TN/z9P8A98L/AIUeTN/z9P8A98L/AIVPmjNcx1FLyZvt/wDx8v8A6r+6vr9Km8mb/n6f/vhf8KM/8TD/ALZf1qfNAEHkzf8AP0//AHwv+FVtQhm+xOPtL8kD7q+v0rQzVW/OYFHrIo/WqjuiZfCynpcMv74C5YfMD91f8Kv+TN/z9P8A98L/AIVW004lm9wp/nWhmiW4R2IPJm/5+n/74X/CobmGb9z/AKS/+tX+Ff8ACruaguT/AKn/AK6rUlHFfFKKQ+FkiaZpPNnjTYVHzfvF46V1l9DMIUP2lziRT91f8K5n4l/PY6RD083UoEJ9MsP8K6y/P+jr/vr/ADrrl/Cprzf6HFH+NUflH9TlPH8ctnHomqmdj9i1SEuxUDajZVj/ACrqIoZvtc/+kv8Aw/wr6fSsj4g2gvvAOrQj7ywGZfXKEPx/3zWjoV6NR0+G9Bz9pt4Zc/7yA/1qJa0Yvs2vyf8AmXD3a8l3Sf5r/IueTN/z9P8A98L/AIUeTN/z9P8A98L/AIVPmjNc51FaWGbyX/0p/un+Bf8ACrNMlP7l/wDdNPoAKKKKACiiigAooqhf7pb20tfMeOKXez+W5Rm2gYGRyOTnj0oAv0Vhm8uD4aeTzJPOWdoQR9+QCYoAO25gMZ6ZOeOtWdFlkcXUcqzxCOUBIblw8kY2jqwJyCckcnr17AAkv7W3PlMYIiWnTcdg55qz9itf+faH/v2KrX9wB5Q8uX5Z052HnmrH2of88pv+/ZoAX7Fa/wDPtD/37FH2K1/59of+/YpPtQ/55Tf9+zR9qH/PKb/v2aAOK1eFbHxPdanHCpjspYRLGF4MbJhuK7RbS0dAyW8JVhkEIORWARHdapr0UsUjJIsII2HpsINT+FtQc6P9kuEkaeycwOQhOQPun8sflXOvcrNdJfmv6/A7ZfvMMpdYO3ye33P8zTvLS1WzlP2aH7v/ADzFV7iytkNv/o8X+qZT+7H92pb+6Bs2XypvmIH+rPrXH6J44TWdX1LTrhW821upPspVf9ZBkr+hH6j0rvp05Sg5LoeVUqwhNRlu9jtobK1+zx/6ND90f8sx6VJ9itf+faH/AL9io4bofZ4/3U33R/yzPpT/ALUP+eU3/fs1gdBka3dadoccmoXlvH5FvEGfEY4BcLn9alS3tPtrMsELLksCEBBBXNcz8SJft1jb6WqyqdRu7e1PykHBfcfr90Vlab4mk8O+GdUs9S3Nf6Mptl3KRvBG2E/Qgj8BXdHD89FSju3+Gn6nnSxPJXcZfClv56/obHgq2gvPF3ie8EMb26SQW0Z2jG5EPmD8yK7b7Fa/8+0P/fsVg+DNP/sHwnZ2ksUxuWXzrhihJaR+WyfbOPwrd+1D/nlN/wB+zWGIkpVHbbb7tDpw0HCkubd6/e7i/YrX/n2h/wC/YqC2s7X99/o0P+tb/lmKm+1D/nlN/wB+zUNtdD99+6m/1rf8szWB0FNrS2FrIPs8XFxj7g9avzWVr9nk/wBGh+6f+WY9KoSXIxOvlS/68H7hq/NcgwSDypvun/lmfStJdDKPUqvY2raOA1tCQUAPyCuf+HNvDHoF1pVxDG82lX01qSyAkqG3A/8Aj36V0Juh/ZK/upvur/yzPrXO6TONM+KGt2nlyrHqVtFexrsPVfkbj3PNaw96E4/P7v8AgMxqe7Upz+X3r/NI6/7Fa/8APtD/AN+xR9itf+faH/v2Kjj1GGWSRIxIzRnDgIcqfen/AGof88pv+/ZrmOvch+x2v2//AI9of9V/zzHrU/2K1/59of8Av2Kg+1D7f/qpv9V/zzPrU32of88pv+/ZoAX7Fa/8+0P/AH7FVryztv3AFvFzMuf3Y6VY+1D/AJ5Tf9+zVW7u1EtvujlAD7iSh7CqjuTLYisLO289gbeLlAfuD1NaH2K1/wCfaH/v2KxNA1yy1aOO705pJ4HiIDrGw5DkHgjNbX2of88pv+/ZpzTi7MUJKSvF3Qv2K1/59of+/YqC5s7X9z/o0P8ArV/5ZipvtQ/55Tf9+zUNzdD9z+6m/wBav/LM1BZyfj61g+3+F4o4Ix5mswblCAblBOQfUV1V/Z2wtDi3h+8P4B61yvjOcS+J/CkflyADUBJyhydoPFdTqF0PsbHypuCD/qz611T+Cn8/zOOH8Sq/T8itqdhaXE8ds9vEFlRkb5B0bisL4ZpFceD4UuYImntma3kJQHlGYfyxWtq2pxWUd1fzRTeXZoJG+Q9ACxrzPwH8Rfsvia4sZLDFrrGotKm18tC8hwFHHIzj0ralRnVoS5VtZ/n/AJmFbEU6OJjzve6/L/I9m+xWv/PtD/37FH2K1/59of8Av2KT7UP+eU3/AH7NH2of88pv+/Zrzz0xstla+S/+jQ/dP/LMVZqtLdDyX/dTfdP/ACzNWaACiiigAooooAKgurOG8VBMGzG25GR2RlOMcFSD0NT0UAVDpdobUW+x/KChQolYYwcgg5+9nnd196ktrOG03+SGzI252d2dmPTqST+FT0UAVb77sH/XdP51aqhfi4/dYMWPPTbwfX61Yxdf3of++T/jQBPRUGLr+9D/AN8n/GjF1/eh/wC+T/jQBnaeu7xJrYPQiAf+OGqVuf7N8YLn5YtTh2n/AK6x/wD2P61Y0/7R/wAJJrGDFu/cZyDj7hqv4jtrs2MlxF5ZmsZFu49oOTt+9+GM1z101FTXTX+vkduEacnTe0tP8vxszR8RXq6dos143IgUykHuFUn+lefL4euLT4aaFrmnIW1WwU3Zx1njlJZ0PrwR+XvWx8Qb+e68ERC2eNv7TaOGLaDk7yOPyJrp7u1mttBa2iMIjhhCKNp4CgAd/avVpVPZ0oyXV/gv+HPCrUvaVpwl9lfc2/0sJ4d8RaZ4h09JdMukkZFAkhJxJEfRl6jn8K164LxXoR+xw63o8UMOuWwWeKSBSrTAclHAPzZHHP09a6fQ9WbXtEtdTs3hMVxGGxgnae6nnqDkfhWNSnHlVSG35G9KpLndOpv5dTnvEA+2/E7w5ZdViaW6kHptj+X9TVXxb4TGo+PNN1FOIcBrtM4DlOYzjvzx9Ks2Kz3vxe1GbMZNhpyQ9DgM7bvzwK29SS6Os2YzF83H3T6/Wun2kqUoqP8AL+epyqlGtGbl/N+Wn6G6BgADtRUGLr+9D/3yf8aMXX96H/vk/wCNeeemT1Bbf8tv+urUYuv70P8A3yf8ahthdfvvmh/1rfwn/GgCGfi6lH/TWM/pWjL/AKl/901kXQuRfhcxZZk7H/GtF1ujGw3Q8g/wn/GtJdDOPUhH/IHX/dH86zfEHg2w8R6ja3l5PdwvbxtH/o0vl+YrEHDHGccHpjrVsfajo68w4wP4T6/Wrrm6SNm3Q8An7p/xojOUJ3i7MUoQqQ5Zq6OE8K2tv4X+Id5pFmhisdStRPArMW+eMkEZPPIJNeh1534xW40v+xfEA2Z02dXkKg/6pztf+YrvR9qIBDQkHoQD/jW+JvLlqd9Pmv8AgWOfC2hzUuzuvR/8G4f8xD/tl/Wp6pYuvt/3of8AVf3T6/WpsXX96H/vk/41yHaT1heLbr7FoV3cA4MVpO6/URnH61rYuv70P/fJ/wAa434mzXMfhK5jzGXnVYVCg5JZ1GPyzW+HjzVYx8znxMuSjKXZGT8IjLY/bNJuT88aRXKf7ssatj8CPzr0+vPUgl0X4j6LIhjWPUbCSz6HG6I7gT74wK7vF1/eh/75P+NaYuXPNVP5lf8AT8zLBR9nTdL+V2/VfgyeoLn/AJY/9dVo/wBK/vQ/98n/ABqG5F1+5+aH/Wr/AAn/ABrkO05rxQPM+InhCIcky3D7f92POfwrqdR/48JPw/mK5HXBcP8AFTwurGPdHBdOpAOOUwc11F+Lr7DJkw9P7p9frXVU2p+n6s46XxVfX/21EF3bx3ml6hHOoeOZijKf4l6EflmuW0H4VaJpPiMahHPdT/ZXWSCKVl2q3UE4HOO1dVFHdf2O2Wi5VmPB/wAakszdM7kNDyqH7p9PrUqtUpxcYOyZUqFKpJSnG7Wxo0VBi6/vQ/8AfJ/xoxdf3of++T/jXOdRLL/qX/3TTqrSi68l/mh+6f4T/jVmgAooooAKKKKACqt5dvA8MMEQlnmJCKz7VAAySTg4H4HkirVU72C4a4trm0EbyQlgUkcqGVhzyAecgdqAEXVITpZvnVlVSVZOC28Nt2+md3FTWVz9rtVmHl4YnHlSCQY+o4zWadJnbRjZuluzF/tB3MSpk83zCuMfdzxnr7VcsLaaKa5nuEije4cN5cTFgMKBnJAyTj09KAH333YP+u6fzq1VC/tkPlHdLlp0z+9b1+vFWPskf96b/v8AP/jQBPRUH2SP+9N/3+f/ABo+yR/3pv8Av8/+NAGdpv8AyM2tf9sP/QDWjOFEyM+NrAo2emK4rUvC9xqXifVLzR9Vu9O1C3WFUkSQsrgrnawJ5GRSJ4W8U6nCZNd8Sy28YX/j209SufU72OR+Vbeyg4c3OvxuYKtUjPl5G/PS3/AMuRGn8YaD4a5eGw1GS7V+o8tV3pz65JFelXql7CdRyTG2PyrjpfDdj4Sa01bT/tEsKPi8aWZnkKtgb857egrrZLaF7V3SSVlZCQRO5BGPrWEaiSVGO0NvNN3T/T5HXUpybeIlvU38mkk1+vzIEs9mlbmO6XYrbvTA6CuTtbweBPEM0V4jJ4f1eYT29wPuWkzD5kb0Unkdh+eOzhs4zbIC02Cgz++f0+tVE0q0v9Nmsb5HnhJMckbysQw+ma6adRJNS1T3/ryOKrSbacHZrb/g+pieCP8AS9e8V6oDuE2pfZ1YdCIlwMf99V0N5EX1ewYLkDfk46cVm+FPDNpoGkSWVpJM0X2iR1JkYHBPA4POBgZ9q1ZbSP7XB8038X/LZ/T60q006rcdtvwsGHg1SSlvv97uXaKg+yR/3pv+/wA/+NH2SP8AvTf9/n/xrA6SeoLb/lt/11aj7JH/AHpv+/z/AONQ21pH+++ab/Wt/wAtn/xoAivRjVLf0JX+daLfdP0rLvLOP+0Lb5puT/z2b1+tXjZxn+Kb/v8AP/jVy2REd2V1/wCQMv0/9mqxettspT/s4/PiqEdqh0YEtN/3+f8AvfWpr60jMKJum+eRV/1z/wCNH2g+wVNe0pNV0g6bJgC4geDJ/hJX5T+Bwfwqv4D1R9T8I2q3OVu7LNncq3VZI/lOfcjB/GtO9tI1EL7pvllXP75+n51zFrbpoPxOnsmaRbPXoftEOJWGJ4/vjrzlfmz9K3h79Jw7ar5b/hr8jmn+7rRn0ej+e346fM7D/mIf9sv61PVL7JH9v+9N/qv+ez+v1qb7JH/em/7/AD/41ynYSl1VlUnlulcV4+H2nVvDlh1FxqcJceqKST/IV0V/a/vohE025AX/ANc/b8a5jVIo7/4peHYUaQpBbT3LgysSMrtHOcjmuvDq0+bsm/wOLFO8OTu0vvaJfGtrdNpekajp9vJcXOm3guRHEMu6A/MoHfI/lW1Z+NPD97pD6lHqcMcEX+tErbHjP90qec/z7ZqZLVAtmd0332H+uf8AxrP1PwX4fv8AWYbmfTY5LtjueVmY5A7kZwT7mlGVOUFGpfTsOUKkZynTtrbR/n/X4B4U8Yab4jvbyGylcyRkSBZEK71PG5Qeo6D/ACK6C5/5Y/8AXVa5fxb4Wa6a01HQ5WtNWtDtt5i5ww/55tz908j2z9apN4xjs3gh8V6VqWiy+YuZnkaS3J9pFP8An1pypKp71L7uv/BFCs6V4V38+j/yLd+PM+MOkqOfK0yVz7AtiurvEaS0kVBliOBXGRfZb/4vQPbXBmgGgmWOSKcsGzPj7wPSuy+yR/3pv+/z/wCNTWuuTyX+ZWHs+d92/wAkKse2yEfcR4/Sq+mnKv8A7qj9Kn+yR/3pv+/z/wCNUNLtY/3y7pvlIH+uf396w6HTs0a1FQfZI/703/f5/wDGj7JH/em/7/P/AI1JRLL/AKl/9006q0tpH5L/ADTfdP8Ay2f/ABqzQAUUUUAFFFFABRRRQAUUUUAUL+6gHlKZVys6ZGenNWPttt/z2T86Zffdg/67p/OrVAEH222/57J+dH222/57J+dT0UAYWnXUA8SawxlUBvIwc9fkNaxvLY9Zk/Os7Tf+Rm1r/th/6Aa2KAM8TWc9rNa3EiPGQUZSeqmsfRdRWwjuNEvZgWtlJtpSeJYu34jp/wDqroZcxS+aBlSMMB/Os7xDpZ1GxW4tG2XtrmS3kH6qfYjiuecWrTjuvxR20pxadOfwy69n3/z8i9De232eP98n3R39qrtMFuZDBcRIkmCSecH2FM0LWYtTt/KZTBdwALNbvwyn19x71q1vCakuaJyVaUoS5ZqzRUt57aCLYLhW5yST1NNlvLf7XB++T+Lv7VdqCX/j7g/4F/KnuTsH222/57J+dH222/57J+dT0UAQfbbb/nsn51DbXlv++/fJ/rW71dqC2/5bf9dWoAqXl3bm6tSJl4f1+lW/ttt/z2T86keJZGRm6ocin029ESlZsxG1K2h0VR5iszHAUHk/NU76na3F1bqsm0qxZg3GMCnfZPJs3eTlz0H90ZrSwCQSOR0qm1clJtK5Qv7u3Nm5EyZUgjn3rJ8V6cmuWFvLp17HbalYzC5s5W5XeB91v9k9/wAPpXQXS7rSUf7Bpbdt1tEfVB/KnCbhaS6CnCM7xlszm/Dfi2DWpnivkFjqdsmy6tXP3Wz95T3U9Qf8nofttt/z2T86wvEPhW213UI7mKaSw1OCLNvfW5w6HPQ/3l56GmeGNfvpNSuvD/iQRrq9oA6yRjCXUJ6SKPXsR/8AqGkoRmnOn8129PIyhUnTkqdXrs+/r2f4P8DW+3W39ou7ToFjiwSTwOc1yWj3djefFfULq2u4Zre001YEdHDKGaTcQCO4ximz2EXjnx5eWt4Gl0XSPkljDlVnuD2OMZCgfn9a7TTtI07SITFpdjb2iHqIYwu7646/jWj5aMWn8TX3Ga5q8018Kf32/S/5FUXlv9ntD5ycS+vuamjvLd9QlfzlwihBz+NB4sbY+koP6mp7H5oXlP8Ay0ctXN9m51fasRXlzbyWjgTLuA3DnuKo3k8epQos8kaQM4HlsA2/6g9vatyoLn/lj/11WkpWKcU9zl9B8O6NofiS4v7BFtHltzG8aN+7PzA5UHp06Dj2rqPttt/z2T86nopzqSqO8mTTpxprlirIg+223/PZPzqhp15brc3oMy8S8c+1a1UbIFdTvxjjchH4iktmU90T/bbb/nsn50fbbb/nsn51PRUlFaW9tvJf98n3T3qzTZf9S/8AumnUAFFFFABRRRQAVnajGlxqFjb3Kh4JC5aNhlXYLwCO/c49s9q0aiuLaC7j8u6hjmQHIWRAwz680AZVtfS2fhtp/KlndJZI4lRGkJHmMqEhQSQBjJ9BUfhW4WaG/QPdSMl22XuIZIySQD/GB3zwOlbUdtBCVMMMce1BGu1AMKOi/T2pyRpHu8tFTe25toxuPqfemBSv5Jv3QEAIE6YO/rzVjzbj/n3H/fwUy++7B/13T+dWqQEHm3H/AD7j/v4KPNuP+fcf9/BU9FAGFp8k3/CSawRACT5GRv6fIa1vNuP+fcf9/BWfp3/Izaz/ANsP/QDWvQBB5lwetsP+/gqrNJcW8Mn+j/uip48z7taNRzjNvJn+4f5Umhp2MS+0p9SjgurZTa30KDyrmOQZHHRh3HtUUXiS60+RLXxDai3lPC3Ib9zJ+PY/X9K24raIwRkDado5U47Uk1u0sLRTxx3MLDBSQDn+lYSptPmho/wZ1wrRcfZ1NV06Nej/AEeg5Z5nQOkCsrDIIlBBFRSy3H2uD/Rx/F/y0HpWOdDawYyaHe3GnHOTBIPMhP4Hp9ajfVNds7iFr2yt71FzzaMysRj0bqfYUe2cfjVvTX/g/gP6qp60pJ+uj/HT8TovNuP+fcf9/BR5tx/z7j/v4Kz7LxPpd7J5Rn+zT5wYLkeW4Ppz1/CtckAZJwOua1jOM1eLuc1SlUpu01Yg824/59x/38FV7WeZvO2wA4lbP7wVR1HxNZQv9ntnN1MxwIbb53Y+nHSqdrc+Io980OkQbS5zF9oAYex7ZrN143stfTU6I4Oo43lZX2u0vzOi824/59x/38FHm3H/AD7j/v4KxP8AhJ7u3/5CGg3sXqYSJcflirln4o0i9fy47tY5ehjmBjbPpz1/Cmq9Nu1/v0/MmWErxV+W68tfyuWbyW4+yP8A6OO3/LQetTebcf8APuP+/govObN8e386nrY5SAyTkYNsP+/gqmtzNYu0ckH7o5aM+Z09q06a8aSAB1DAHIz600+5LXYyEjubi+Ms8DKzR/Kqy42jNYfijRNR1FEudJBi1rTWM1nMZAS6kYaM56g+/f2Jrrv+Yh/2y/rUV/mLZcJ1XKt9DWtOpKMroyq0ozhZmN4M0ubQ/DMNsYfMmdmlnlMnMkh+8xPf/ACt7zbj/n3H/fwUtmuyziH+yD+dTVFSTnNyfUunBQgoroY80k50df3AwD/z0HrV2A3EdvGn2YcKM/vBT7RQ1mgYAjngj3qxU30sVbW5B5tx/wA+4/7+CobmW4/df6OP9av/AC0FXaguf+WP/XVaRQebcf8APuP+/go824/59x/38FT0UAQebcf8+4/7+CoYpbj7XP8A6OP4f+Wg9Ku1BF/x9z/8B/lQAebcf8+4/wC/go824/59x/38FT0UAVpZbjyX/wBHH3T/AMtBVmmy/wCpf/dNOoAKKKKACiiigAooqne3EyTQW1r5YlmLHfIpZUCjJOARnqB1HX2oAuUVQgvp7rSxNbwq0/mGJlLfKpVyjHPcDBPqak0+5mn8+O48tngl8vzIwQr8A5AJOMZxjJ6UAR38Mh8o/aZADOmBtXjn6VY8iX/n6k/75X/Co75l2w8j/Xp396tb1/vD86AIfIl/5+pP++V/wo8iX/n6k/75X/Cpt6/3h+dG9f7w/OgDD0+KQ+JNYAuJAR5GTtXn5D7VreRL/wA/Un/fK/4Vm6cw/wCEm1nkf8sO/wDsGtjev94fnQBD5Ev/AD9Sf98r/hTJoJfs8n+lSfdP8K+n0qzvX+8PzqOdl+zyfMPunv7UARQwS/Z4/wDSpPuj+FfT6U/yJf8An6k/75X/AAp0DL9nj+YfdHf2qTev94fnQBD5Ev8Az9Sf98r/AIVBPbyNcwBrmQg7uqr6fSru9f7w/OoJWX7XB8w/i7+1AFG80GO9j8u4kEyDoJY0OPocZFZyeA9LH3jMAeqJIcGum3r/AHh+dG9f7w/OsZUacneUUzphiq9NcsJtL1M+y0W305dtjiDsSkaAn6nGTUltBL++/wBKk/1rfwr/AIVc3r/eH51BbMv775h/rW71qkoqyMJSlJ3k7sU28hGDdSEe6p/hVG90C3v49tw3mem+NDj6ccfhWpvX+8Pzo3r/AHh+dKUVJWaHCcoO8XY5OfQbzSrVv7L1KeCPj9zL+8iP07rUguPFcX3ora7X1hOzP/fS10N4y/ZH+Ydu/vU+9f7w/OsfYJfC2jq+uOX8SKk/P/NWf4nLjxBqEB/4mOmajCO5hEc2PyArQ07WbLVG2WuqN5vQxSKquPwI5/CtclGGGKke9ZWpaDp+oZM9vFIfXOGH0Yc0ctaOzv6/8D/IFPDVNJRcfR3/AAf+Za8iX7f/AMfUn+q/ur6/SpJbSSWJka6kwwx91f8ACudXTNUtbvytM1mdFCcJcxrLgZ6bj2qwR4ptRlbnT70dw6FD+lCrSW8H+H+YnhYP4akfxX6W/E21t5VUKLqTgY+6v+FL5Ev/AD9Sf98r/hWF/wAJHqtudt5oTH/agnVs/geRTx4uXo+jatn/AGbcN/Wn9Yp9X+DD6lX6JP0af6mpZwS/ZE/0qTv/AAr6/SpvIl/5+pP++V/wrBtvGFhFbqs1tfR4zy1ucdfarcXi7QphxqCKe4kVlI/MU1iKT+0iXg8QteR/cafkS/8AP1J/3yv+FQ3MEv7n/SpP9av8K/4UQaxpt0cW9/bSH0WVc/lUtyy/ufmH+tXvWqkpapnPKEoO0lYXyJf+fqT/AL5X/CjyJf8An6k/75X/AAqbev8AeH50yW4jhTc7D86Ykm3ZDPIl/wCfqT/vlf8ACoYoJftc/wDpUn8P8K+n0p0+pW0GnzXbSKY4kLnBGeB0+tcfpHjyS71xIbi0jSK6kWMFWJKE8D6/pWFTEU6clGT3Oujgq9eEpwjpHc7TyJf+fqT/AL5X/CjyJf8An6k/75X/AAqbev8AeH50b1/vD863OMrywS+S/wDpUn3T/Cv+FWajldfJf5h9096koAKKKKACiiigAqreWks8sE1tMsU0JOC6F1IIwQQCPY9e1WqKAM1dOu4dLe1tLyOKRlJ84wZIkZizNjd7nA7epqxp9tNZ2ohlkhdV4TyoimB75Zsn3q1RQBRv7aA+UTDGS06ZOwc81Z+yW/8Az7xf98Cqt9OT5SiGU7ZlP3euD2qf7Wf+fa4/74/+vQA/7Jb/APPvF/3wKPslv/z7xf8AfApn2s/8+1x/3x/9ej7Wf+fa4/74/wDr0AZenW0B8SayphjIXyMDYOPkNa/2S3/594v++BWVZGSLXNTuGt5tk/lbcLzwuDnmtL7Wf+fa4/74/wDr0AP+yW//AD7xf98Co5rS3+zyfuIvun+AelL9rP8Az7XH/fH/ANemTXZMEn+jzj5T1T2+tADobS3+zx/uIvuj+AelSfZLf/n3i/74FQw3ZEEf+jzn5R0T2+tP+1n/AJ9rj/vj/wCvQA/7Jb/8+8X/AHwKgltbf7XB+4i/i/gHpUn2s/8APtcf98f/AF6hluibqA/Z5+N3G0c8fWgCz9kt/wDn3i/74FH2S3/594v++BTPtZ/59rj/AL4/+vR9rP8Az7XH/fH/ANegB/2S3/594v8AvgVBbWtv++/cRf61v4BUn2s/8+1x/wB8f/XqG3uiPN/0ec/vD0Uf40AWfslv/wA+8X/fAo+yW/8Az7xf98Cmfaz/AM+1x/3x/wDXo+1n/n2uP++P/r0AR3lrb/ZH/cRdv4B61P8AZLf/AJ94v++BVa7uibVx9nnHTkqPX61N9rP/AD7XH/fH/wBegB/2S3/594v++BR9kt/+feL/AL4FM+1n/n2uP++P/r0faz/z7XH/AHx/9egCP7Lb/b/9RF/qv7g9an+yW/8Az7xf98Cq32o/bs/Z5/8AV9No9frU32s/8+1x/wB8f/XoAf8AZLf/AJ94v++BR9kt/wDn3i/74FM+1n/n2uP++P8A69H2s/8APtcf98f/AF6AI7O0tzaJmCLv/APWlk0rT5TmSygY+8YplpdEWqD7POevIUev1qb7Wf8An2uP++P/AK9JpPcak46plK58MaPcrh9PgU+qIFP6VmzeCdGj8vZDIm5wDtlbn9a3/tZ/59rj/vj/AOvUNxdE+V/o84/eDqo/xrJ0KUndxX3HTHGYiKtGb+9mQ/gq2Xmzv72Bv+uuQfrkUQ+DYJX36xdTXpH3ULbEA+i45rd+1n/n2uP++P8A69H2s/8APtcf98f/AF6X1el2/wAvuK+u4j+bXv1+/cy/+EM0DzN/9njPp5j4/LNUtN8E6ZZ6w04aaUQsGjjkIKgn145xXQ/az/z7XH/fH/16hiuiLqc/Z5+dvG0ccfWj6tRunyrQPr2Ks4+0dn5ln7Jb/wDPvF/3wKPslv8A8+8X/fApn2s/8+1x/wB8f/Xo+1n/AJ9rj/vj/wCvW5xhLaW/kv8AuIvun+AVYqpLd/uX/wBHnHyn+D/69W6ACiiigAooooAKKKKACiiigBkkYk27s/KwYYp9FFABRRRQAxYwsjuM5fGfwp9c9ZDbJpdxGP8ASLmaRbl/4nG1yQfXDAAenSuhoAKR1DoynowwcUtUdYh+06a0G+JfMkjU+acKw3jK/j0x3zQBdRQiKo6KMDNLWdo4jiS5to7WG3NvNsYQDCMSqtkDtwRxWjQAUxow0iOc5TOPxpzKHUqcgEYODg/nWAEEdg9vvkMJ1ERN5kjOSpYcFiSSCeOeuaAOgorN0lfKm1CCNQsENwFiReijy0JA9BknitKgApkcYj3bc/MxY5qhrsQfTWk3SK0TKy7JWUZyOoB5+hzVTWrZHupryaGzu0tbXf5E3LDliSOOMgcH2oA3aKRCGRSBgEZANLQAyWMTRlGyAfSn1hy26DUHew3NcW5eSe4JyWyrbYs98ZBx2AHrSaYiQ32n/ZcbLiyaSZgeZGBjw7ep+ZuaYG7RRVe/SF7J/tMpihXDyMG2/KDkgn0OMH2pAS+WPO83ndt2/rT6586cJrJIgkMFvPdCSO0nGFCBPu7fUkbtv1rS0d0bTwsdvHbiKR4zHF9wFWIJHscZoAvUUVh6/CJIbmWFUmuIYckPLtNuvzfvEGPv8HuM7cZFAGzFGIYwi5IHrT65t8Okt6vzXa38UaSNwyoWQbfYFSTj3rpKACmSRiTbuz8rBhinHhTk4461zZiFvcn7O0UME1jKY7rzS3nnC/PKcDGM5B56np0IB0tFZGjwRWN3NZJaW8LrFHIZLcYDg7hz7gg8981r0AFMWMLI7jOXxn8KpaxevZ2i+Uk5eZxHvhgeUxjuxCgngDj3xWFoJt9RtLWGcSyQRQTFFukdSWEmN3zgEkDHzdsmmB1tFUtGklm0OxkuCTK8CM5PUnaKu0gEdQ6Mp6MMHFLRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBBHZWsVy1xFbQpM+d0ixgM2euT17D8qnoooAKZLDHcQtFPGksbDDI6gg/UGn0UARwW8NtH5dvEkSZJ2ooUZPU4FSUUUAFRPbQSQyRSQRvHJkujICHz1yO9S0UARwW8NtEIraJIowSQsahRknJ4FSUUUANeNJUKSKrqeqsMg1FPZWt1Ir3NtDM6fdaSMMV5zxn3AP4VPRQAUUUUAVE0rT47k3CWFss5YuZRCoYsepzjOfepLextbV3e1toYWk++0cYUtyTzjryT+dT0UAFR3FvBdwNDdQxzRN96ORQynvyDUlFAFVdL09IWhSxtliZgxQQqFJHQ4x1qeKGOCFYoI1jjQYVEUAKPYCn0UAFQT2NpdSK91awzOowrSRhiBnOOfcD8qnooAgaxtWuxdNbQm4XpKYxuHBHXr0J/Op6KKACq8On2duztBaQRM4IcpGBuBOTnHvzViigCG2s7azVltLeKANjIiQLnjHb2qaiigAqtLp1lPCsU9nbyRoSVR4lIUnrgY75NWaKAADAwOBRRRQAUUUUAFFFFAH//2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "_TA2OiNGpZNh",
        "outputId": "b8204260-9a2b-4d96-a8a1-fca14c0036d6"
      },
      "source": [
        "Image(filename='/content/drive/MyDrive/EffnetB2_metric.JPG')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFyY2hpc21hbiBEYXMAAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzg1AACSkgACAAAAAzg1AADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjA3OjMxIDE4OjI2OjA5ADIwMjE6MDc6MzEgMTg6MjY6MDkAAABBAHIAYwBoAGkAcwBtAGEAbgAgAEQAYQBzAAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjEtMDctMzFUMTg6MjY6MDkuODQ3PC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPkFyY2hpc21hbiBEYXM8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA9gFpAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaz9U1u10p4Y5lnmnnz5cFtC0sjAfeOB0AyOTxyB1IrQrmfE3h251LVrHVLKGC6ktopIGtp7qS3V1cqciRAxBBUcEEHPagCxL4x0tFtzAt5dtcwG4jS2tJJG2A4JIA+Ug8YOD268U6XxdpaQWslubi9+1Q/aI0tLZ5W8r++QBkDtzzngCsOO01XSfEVnBo9hpzTLpcm+F7mSOJSZgeH2Mx5PcDPXjpU9h4b1nw99mn0f7BfXBsxbXKXMrQLuDs4dCqOcZkYbSBxjnigDXuPFmlwx27wNPei4h+0ILO3eYiL++Qo4H6nnAODWZ/wnFpb6rqBnaefT4reC4jmtrV5FjjdSS7MBwOB7+1MsfDer+Hmt5tH+w30rWa21wtzK0Chg7PvUqj8Zkb5TjjHNWLvw3qF1p+vxSXFs8+qWCW6OAUXzBGykkYO0ZbtnigDp1YOoZTlWGQR3rm9B8Uxz6SkmrTBbjy7idiEwpiilKk/UDb+dWF1bUbOSOyHhnVLhIgsf2qKW18tsADcA0wfH1UH2rIbwVeSaLpdobi3SW2u5TcsMkSW0jszxjjqRt/KgC5rfi+3TwxJeaNNvnlsfttuxjJHl7lGTnp97off0q8/irTor68tHF0XsV3XMiWrtHH8oYDcBgsQwwoyfasWXwVeGw8Q28dxbn7fiOxB3AQxbjIVbg/xu/TttrRuNB1I2fiBbK6jgn1GVZLeRXZSoESIQSBlc7CMjJAOetAEzeMNMjtbma5W7t2tWjEsMtq4kHmNtQhcZYE8cZ7jrVvStdtNXkuIYEuIZ7YgSwXMLROoblWww5BwcEeh7iuI1HQNWsIb7Up7awt2uX0+KK3hupZwrJc5yzsikg7hzj1+p63RtO1Ea1fatrCWsE9xFHAkFrM0qoiFjkuyKSSXPbgAUAblFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVk3uvpZ+JLHSGtJ3N5FJJ56oSibccHj3/Dj1rWrM1DSZLzV7G+guhA1sksbqY929HAzg5G1gVGDz34oAhPirTEjmeZriAQxCbEts6s6FtoKqRlsnAwOckcciprLxBZ388sMUd2ssMqxSJJayKUZl3DPHTH8XTtmuYTwHJYwXNwZ7ee5+zLGhs7BY5JHSRZFkkLSfvHyvOSM+1anhyz1kX2o3+ovHG11cRnm18vfGkYXhfMYpz3JPQ8c0Aad/4gsNOuWguXk3RqrytHEzrCrHAZyBhQSD+AJ6DNRx+JtOkv/soNwrfaGthK1u4jMq9V34x2PfHbrxWfrHgu31TXjqZTTpDLGkcy3uni4bCE4MbbhsOCRyGHQ49Y7Pw9qFxcyC+uY4tPTUpbpbYQHzH+YlP3m/G3nONufegDSj8WaS6NI00kcQieZJZIXVJUT7zISPm/DqCCMiq154thiktBBDcbnukhmhktZBKFaN2UquMnJXryBznGDiqfBUlxZRWN/qSy2dpbvBZLFb7HjBAUM7FiHIAA4Cjrkemkmj6lPNazarqkVw9tcCZVgtPKTARlxguxyd+SSSOBgCgDQ07UbfVLMXVoWMZZkIdCrKykqykHkEEEVlweKLeKO8OpssJt3uWBVDgxQvgnvluRx3zRbWWr6LFJb6Zb2N9FJPNcGS4ungZTJIz7dojfIGcZyM+gqObwotysHm3RUx6g944VPvq7FjEeemcc99vSgCe48Rwtc2MenssonmiEjFTgRyI7KQfX5PyPvRH4s0+WwW8jivmgZWcMLOTlFGS3Tpz179s1DZeE0so0RLtn2agbsFo+i7CixDnoqkDPt05qnqPglr3StPsPtlrJFa2zW7reWXno2QP3irvAVxjgndjJoA1H8V6XHcGPfOyKYt8yW7tEnmAFCXAwAcj6Z5xWzXGweFtSZ7ywa9ji05xbRyE2xLzrHEgO1t+EyVwchvauyoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiqmoLtsppFZ1YDgq5GKALdFN8tfVv++zR5a+rf99mgB1FN8tfVv++zWXp7PJrurxvLIyRPEEUyHC5jBOOfWgDWopvlr6t/32aPLX1b/vs0AOoqvdLthBVnB3oOHP8AeFTeWvq3/fZoAdRTfLX1b/vs0eWvq3/fZoAdRVeBcyXALOcSYGXPHyrU3lr6t/32aAHUU3y19W/77NQ3K7Vj2s4zIoOHPrQBYopvlr6t/wB9mjy19W/77NADqKb5a+rf99mobdd3m7mc4kIGXPFAFiim+Wvq3/fZo8tfVv8Avs0AOoqvcLtaHDOMyAHDnng1N5a+rf8AfZoAdRTfLX1b/vs0eWvq3/fZoAdRVe2XdGxZnP7xxy5/vGpvLX1b/vs0AOopjKiqSzMAOvzmoJNplt9jttZyDhzz8p96ALVFZ2pXttYQGS5nMMa8u+85+g9TSaNf2+q2AuLaSRl3FSGY7lPoRnrUe0jzcl9TX2M/Z+0toaVFN8tfVv8Avs1DaLutwWZydzclz6mrMixRTfLX1b/vs0eWvq3/AH2aAHUVGF2zLgt909WJ9KkoAKKKKACiiigAooooAKKbLLHDE0kzrHGoyzOcAD3NN+0Qi3+0ebH5O3d5m4bceuemKAJKo6pcRrZTod24L2RiPzxU1tf2d6WFndwXBX7wikDY+uKbqX/IOm/3f60AP+2Rf9NP+/Tf4UfbIv8App/36b/Cp6KAIPtkX/TT/v03+FZOm3MY8QayTvwzw4/dt/zzHtW7WRpn/Ixa3/10h/8ARQoA0PtkX/TT/v03+FH2yL/pp/36b/Cp6KAKV3dxeQP9Z/rE/wCWTf3h7VN9si/6af8Afpv8KLv/AI9x/wBdE/8AQxU9AEH2yL/pp/36b/Cj7ZF/00/79N/hU9FAFK3u4vNuP9Z/rf8Ank391fapvtkX/TT/AL9N/hRb/wCtuf8Arr/7KtT0AQfbIv8App/36b/CoLq7i2x/6z/Wr/yyb1+lXqguvux/9dU/nQAfbIv+mn/fpv8ACj7ZF/00/wC/Tf4VPRQBB9si/wCmn/fpv8KhtruL99/rP9a3/LJv8Ku1Bbf8tv8Arq1AB9si/wCmn/fpv8KPtkX/AE0/79N/hU9FAFG5u4t0H+s/1o/5ZN6H2qf7ZF/00/79N/hTbt1R7YMeswA/I1ZoAg+2Rf8ATT/v03+FH2yL/pp/36b/AApZJGMgjhxu6sT2qC61FLCPdevDEOzPKFz9M1Lklqy405SdluFpdxeU/wDrP9a//LJv7x9qlN7AoyxcD3jb/CsCDxnpiK6IZJn8xziKNmzliR2pRca/q75tbNdPhPSa75YD2j9frWP1iD+DX0OpYKqtai5V56f8H7i3qWv2VqFMxkbJxFCsZ3zN6AGsue/1m+uIvs2mppwLnD3DMxPyn+FRxxmtrTNAhsJ2u7iWS9vnGGuZuSB6KP4RV6f/AI+Lb/rof/QGpKnOes3byX+f+Q3WpUtKa5vN3/Bf5/cjCstGiF4t5rF1Jfzx/wCrU27LHGfULjk+5qO9t7iy1pr/AEDaHuBieCWNxHJ/tcDqP8989RUFyrHYY/vZx+dN0IKNl/wfvFHF1XO8nfS1ulvQ5xPE1/YXitr0MMdlJ8omt0ciNvfPUH2rS0jXtNvoSlpcea6EllWNsgEnnGKh8V6PLqfh429pjzInDgE43Y6j9c1jeB/Dt9p99Jf3qrEjRGNFDgluRzx24rBTr06yp2vF9f8AgnY6eErYWVZvlmui6/Lc7D7ZF/00/wC/Tf4UfbIv+mn/AH6b/Cp6K7zxiBJ0luFCbs7SeUI7j1FT00/65f8AdP8ASnUAFFFFABRRRQAUUUUAZ2rukTWMtwwWBLoGRmOFX5WCk/8AAiv44pmjTRFLjZLGUmuZZIArD50yMkeo3E8+/vWpRQBQ03/SXm1A9Jzti/65rnB/E5b6EUuqGf7FPtSMpt4Jcg/lir1VdS/5B03+7/WgB+66/wCeUP8A38P/AMTRuuv+eUP/AH8P/wATU9FAEG66/wCeUP8A38P/AMTWVprXH/CQaziOLO+HILnj92PatysjTP8AkYtb/wCukP8A6KFAGhuuv+eUP/fw/wDxNG66/wCeUP8A38P/AMTU9FAFK7a68gfuof8AWJ/y0P8AeH+zU266/wCeUP8A38P/AMTRd/8AHuP+uif+hip6AIN11/zyh/7+H/4mjddf88of+/h/+JqeigClbtdebcfuof8AW/8APQ/3V/2am3XX/PKH/v4f/iaLf/W3P/XX/wBlWp6AIN11/wA8of8Av4f/AImobprrbH+6h/1q/wDLQ+v+7V2oLr7sf/XVP50AG66/55Q/9/D/APE0brr/AJ5Q/wDfw/8AxNT0UAQbrr/nlD/38P8A8TUNs11++/dQ/wCtb/lof/iau1Bbf8tv+urUAG66/wCeUP8A38P/AMTQXugMmOH/AL+H/wCJqeorknydo6udopPRDSu7GdcLdXDRSGOIZkwn7w8cHnpVj7VdfZw3lQ7j8uPMPX/vmqOtapJaXllp+nQLcXkh3hGbaFUAjJP+elVW0fV9YmI1iWK0tDy0NoxLSexY9B9K55VLPlgrv+up2woXipVGox6d7em4w3+patcSWOiNHFHG3+kX4bcM/wB1Mjk+9WrTwxb28nnT20d7cHlpruYyMT+K4rZtbWCytkt7SJYokGFRRwKmqo0VvU1f4L0Jnimvdo+7H8X6v9NkUbL7QkDKkMCqJHAAkIx8x/2an3XX/PKH/v4f/iaLT/VP/wBdX/8AQjU9bnGQbrr/AJ5Q/wDfw/8AxNQztdefbfuof9Yf+Wh/ut/s1dqCf/j4tv8Arof/AEBqADddf88of+/h/wDiaN11/wA8of8Av4f/AImp6KAICboggxQ4P/TQ/wDxNV7D7UlmqiOIgM3WQ/3j/s1fqCz/AOPUf7zf+hGgA3XX/PKH/v4f/iaN11/zyh/7+H/4mp6KAIEMxuF81I1G0/dcnuPYVPTT/rl/3T/SnUAFFFFABRRRQAUUUUAFFU9QmlQ20MD+W1xN5ZkABKDazEjPGflxz61Xh1JodLvprnMrWLSKxC4MgUZHA74I6d+1AGpVHVId1jO3myDK/dDcU3S7uWbdHdmQXO0SFHjCqFPGVxk447nPrjin6nPEtjOrSoGC8gsM0ATfZj/z3m/76/8ArUfZj/z3m/76/wDrU77Vb/8APeP/AL7FH2q3/wCe8f8A32KAG/Zj/wA95v8Avr/61ZOmwZ8QayPOlGHh5Ddf3YrY+1W//PeP/vsVk6bcQjxBrRMsYBeHB3Dn92KANT7Mf+e83/fX/wBaj7Mf+e83/fX/ANanfarf/nvH/wB9ij7Vb/8APeP/AL7FAFe7tj5A/fzf6xP4v9oe1TfZj/z3m/76/wDrVFd3MHkD9/H/AKxP4x/eFT/arf8A57x/99igBv2Y/wDPeb/vr/61H2Y/895v++v/AK1O+1W//PeP/vsUfarf/nvH/wB9igCvb2x824/fzf63+9/sr7VN9mP/AD3m/wC+v/rVFb3MHm3P7+P/AFv98f3Vqf7Vb/8APeP/AL7FADfsx/57zf8AfX/1qgurY7Y/383+tX+L3+lWftVv/wA94/8AvsVBdXMG2P8Afx/61f4x60AS/Zj/AM95v++v/rUfZj/z3m/76/8ArU77Vb/894/++xR9qt/+e8f/AH2KAG/Zj/z3m/76/wDrVDbWx/e/v5v9a38X/wBarH2q3/57x/8AfYqpZX9s7TDzowfNbGWHIpXHZss/Zj/z3m/76/8ArVTvWis1kubi5mWG2jLsdw/L61Zkv4Adkc0bOf8AbGB9a5+9eHWdcj0wTo9nbET3j7hiRv4Y/wCp/wDrVlVm4q0dzpw9JTleeiWr9P60XmJpdnKfJ1XUHkW71Cddq7uY48Hav+fauk+zH/nvN/31/wDWrJ1S5ikuI3SaPbbuuPmHJ5rYF3blQRPHg/7YrWNNU4JIwqVnWqOT+Xp2+Q37Mf8AnvN/31/9aj7Mf+e83/fX/wBalW7tmXKzxkf74pv2+187yvtEe7Gcbh0pkEVpbHyn/fzf61/4v9o+1TfZv+nib/vr/wCtUVpcweU/7+P/AFr/AMY/vGoGnS6neWK5jTyvlj+cYY96aVxN2Ln2Y/8APeb/AL6/+tUE9vi4th9om5kP8X+w1SW+oQTId0saOpwylxwaydb1fTba8tjfalb2sUZJ3vKF+YqenrVRi27Eymox5mbP2Y/895v++v8A61H2Y/8APeb/AL6/+tWRoPi3SddkuYbK/ine1273GVBznBGQM9O1bP2q3/57x/8AfYpShKD5ZKzCE41I80XdDfsx/wCe83/fX/1qgs7Y/Zh+/m+838X+0farDXduqk+fHwM/fFVNJu4m0yMyXEZYlicuP7xpW0uVfWxa+zH/AJ7zf99f/Wo+zH/nvN/31/8AWp32q3/57x/99ij7Vb/894/++xSGNSHy7hT5kj/KeGOe4qeolmiknURyIx2k4Vge4qWgAooooAKKKKACiiigCveWi3caAyPE8biRJI8blI47gjoSOneoo9MjS2eB5ZZY5A/nB9v70t1JwBj2xgfpV2igCpaWH2aVpZLma5kKBA823IUdvlAo1JFOnzEqM7euKt1R1SVxYzqLeRht+8CuD+uaALnlp/dX8qPLT+6v5VF58v8Az6Tf99J/8VR58v8Az6Tf99J/8VQBL5af3V/KsnTEX/hIta+Uf6yHt/0zFaPny/8APpN/30n/AMVWVps0g8QayRbSEl4cgFeP3Y96ANry0/ur+VHlp/dX8qi8+X/n0m/76T/4qjz5f+fSb/vpP/iqAG3aJ9nHyr/rE7f7Yqfy0/ur+VVLueTyB/okv+sT+JP7w/2qm8+X/n0m/wC+k/8AiqAJfLT+6v5UeWn91fyqLz5f+fSb/vpP/iqPPl/59Jv++k/+KoAbbonm3Pyr/rfT/ZWpmEalQwUFjgcVTiuXRrpmtZsCTJ5T+6v+1Sb5bhWkNrMCfufMnH/j1JvsVFJ7l7y0/ur+VQXSJtj+Vf8AWp296SK7kkjB+yS5HB5Tr/31Ud1PJtj/ANEl/wBav8Sev+9T3E1Z2Lnlp/dX8qPLT+6v5VF58v8Az6Tf99J/8VR58v8Az6Tf99J/8VQILgKECKq7nOBxVYJawWk73BSKKNyTI2Bt980S3vlGa5nt5FigU5YsnGOSfvVzulQSeJZH1DU4ZpbQTFrezUqEx2Zsn5jWMpO9oq7OqnTjbmm7Jfe32Ra+0XXiDMGixmz0/OJL5lw8g7iMf1rZtbCy0XT/AC7aJVjXkk8s59Se5qdZnRQq2cqqBgAFMAf99VWE0t1dEm1lMUJwBuTlv++qqnSSfNLV/wBbEVsQ5R5IK0e36t9f6sZ2r6lpuiWdn/bE8dsby42hnHG4qevoBxz0Ga0Dd29toRu5njjjjj5kYgAY4yTXGW0aeNPFd1q19ZtdaTasdPs4m2lXOD5r8n6AEdvpTLfwMTqa6deXN/daHbyebBpjuu1e+GbdllHGB/k+k6VJaTlZrV/5LzPHVas/ehG6ei/zfl6HY+HNRsdX0oT6fNHcQhyodB/kiqw1bTj4r+wfaIvtmCfI77emfz7Vzeq6ZrHhjW5b/wAF2CrDeptuLByojV+glUA4GOMjpjP4QS+B5oPDSahaiZvEscovP7Qdl/eSd0PzfcI4x/8AqpqlSvzc2ktu/wAxOtXty8usd+zXl5s7wkR2MpRV3NK6rx3LmuTW81TxVqdxYeGL1NO0mx/dT6isIkeeXuseeAB/erNTVtf8cWsWm2NjPpFtuf7fdMBv3ZO5IgSOhyN38sc93pdnDo2mQafp+nyRW8C7UUMn5n5uSepNQ4rDr3tZffb+uhopPEy926h32v5Lrbucnc+Gtd8LSLf+HdVm1Pfxc2mqPvEx9Vfjaf096l0Twmby+i1zxasV7qNzIQsDKGhtk2thVU8E+/t+J6+Z3mhaNrSbDDHVP/iqieR43tEFpLhXIHKf3G/2ql4mbjbr362LWEgpX6dulzltSjh8P/E/SbuKJIrXVIDYyhVAUODujOPUkYrtvLT+6v5Vx/xBtLjUPD7tbW8qXNqPtMD5X5Xj+bIweuAR+NZ83xYsZLGC4srC+mjXY13MkX7uAHGRuPUgmtHSnXhGUFd7P9P8vkZKtDD1Jxm7J6r9f8/mdrqtza6fpVxc3bxQQxod0jkADPHWs/wzrWj6vYeXpd5b3Lw/6xUPzLknBI61zfxXkOofD3zIQyxmeKRG3KRKDkADBOc5z+FYfwp8Ja5omtz6pqVjJBA1u0KpvXc5LKemeg204Yem8M6kpWd9ETPE1Vi40oxvG2rPW/LT+6v5UeWn91fyqLz5f+fSb/vpP/iqPPl/59Jv++k/+KrgPSH7VWZcKB8p6D3FSVAkrvcKGgeMbTyxX1HoTU9ABRRRQAUUUUAFFFFAEVxcRWsXmTttXIAwCSSegAHJPsKIbmK4g86F9yc84xjHUEdQR6VV1QMrWU+x3SC43OI0LEAoy5wOTgsKgsc/ZbvfFPi6llkjTyyrbeB34UnqAcdfrQBcstRttQBNqZGAAO54XQEHoQWAz+FGpf8AIOm/3f61S0kutz5cBujZrboMXUZQq/oMgduvYYGMVZ1RJjYzlZgF28Lsz+uaAL1FQeXcf8/C/wDfv/69Hl3H/Pwv/fv/AOvQBPWRpn/Ixa3/ANdIf/RQrQ8u4/5+F/79/wD16ytNjnPiDWQJgCHhydnX92PegDcoqDy7j/n4X/v3/wDXo8u4/wCfhf8Av3/9egAu/wDj3H/XRP8A0MVPVK7juPIH+kL/AKxP+Wf+0PepvLuP+fhf+/f/ANegCeioPLuP+fhf+/f/ANeq4hubhy4utoXhCI/160mykrjbiXy1uQOrS/8Asq1kjUL/AFO8XTdFuFthbLm6umjD7T2QA8Z71Brd3eWm6CGVZL+7uFhgjCf7K5b2A4rS8PaVJpenvbR3ALrKxkcpkux6nrWUr1PdXz/yOiFqK55K/Zfm/lsvP0Kko1rw/OLqS5bV7Z/9egjCOn+0oHX6f/rGyt5DqFhbXVq++KV0KnHvUk1vcSRkfaFz1H7vv+dc1pnm6fqk2kiUJFJIt1bfJxgthlHPGD2qFelNK/uv8GayaxFJyt70e2l16LS6/K519Nlfy4mY9hxURSdVJNwoA6/u/wD69Yeras9mqqswnvZB/o9okeWY9iRngVrUmoK7OajSlVlyxRX12VtQuItDtySoxLesvYfwp9Sf5Vr6TELWee3Xhc5AHtxVHSdHnsXjSW4V7mTNxcOUyWc++eg7VbSO4S9V/PX5pXQ/u/y706MWleW7/pL+uoYmpFyUIfDH8X1f9dEjTnl8mB5D/COPrXJeKNSulhtPDOitjVtUU75P+faH+OQ/qB/iKv8AifV10PTHur25BjiG8oIxlz/Co56k8VV8IaDqEC3GuaxIo1fVCHmBTPkp/DEOeMDGff1xXbSShH2svl5v/gbs82tJ1J+yj8/Jf5vZfN9DYsdKttE0rT9Osl2w27BFz1PByT7k5J+tX1gC3Uk3dgB/n9Kr3Mdxug/0hf8AWj/ln7H3qby7j/n4X/v3/wDXrmcm22+p1KKSSXQi1GF5Y0MQJYEjj0I5qw8QNs0Q6bNo/KmeXcf8/C/9+/8A69Hl3H/Pwv8A37/+vRd2sHKr3KGiZkWSQj7pZB/30Sa1qz7C2ligcRzKAZnJ/d/7R96s+Xcf8/C/9+//AK9OTuwirKxPUE//AB8W3/XQ/wDoDUeXcf8APwv/AH7/APr1DPHcefbf6Qv+sP8Ayz/2W96kofegZgYjI80Ag+hqvcWFtcbrDyIxbfZ2TygoC4bjGKffxXH2Nm89TtIP+r9/rSW0c8l1cSC4XqFH7v0H1rRNpXRlJJyszz7SPDurHxLpuj37NNoGlyG8tGYcuT91GPfYQ34exFelWf8Ax6j/AHm/9CNZ0ENwNTaPz1xGWYfu/XHvVuzjuPsw/wBIX7zf8s/9o+9aV6rqNNmWGoxpRaX9eXyLtFQeXcf8/C/9+/8A69Hl3H/Pwv8A37/+vXOdRKf9cv8Aun+lOqBElW4XzJQ42ngJjuKnoAKKKKACiiigAooooAKKKKACqupf8g6b/d/rVqqOqW0L2M7tGCxXk0AXqKg+xW//ADyWj7Fb/wDPJaAJ6yNM/wCRi1v/AK6Q/wDooVofYrf/AJ5LWVptrAfEGsqYwQrw4Hp+7FAG5RUH2K3/AOeS0fYrf/nktABd/wDHuP8Aron/AKGKnqld2dv5A/dL/rE/9CFTfYrf/nktADb6Xy7c+pqnqGtQ6XbW8axPcXU6/ubaIZZ+OvsPeoryK18xnkVVhjRmZj2AHWqHhWwW/R9Zu4gDcDZbIf8AlnEOn4k81lNuyUd3+COmlGOsqnwr8X2/zHaZptw2sHUdW2G+kk2hE5WFQoOB788mt63+W7uU/wBoN+YrA126ttEs9R1FoUb7JG8iqxwGbYoUfiSB+NM8K63p3iRnkS2NtdRxgXNpKCHhf09x6H/9VdNOg40uaK07+ZxVsUqlflk9ei8vI6uuf1nTZrl7a4sHjjvLO4zEZc7SrdVOOcdK2fsVv/zyWqd1aW6XCDylwzIfyNc9SKmrM6qNSVOXNH+v6RnSyeJb9hYtBa2OeZLpH3jH+yvr9a0tK0O10oM6bprmT/W3Mpy7/j2HtUtvZ2775DEvzHj6VN9it/8AnktRCkk+Zu78zWriJOPs4pRXW3X16/oQvPHb3F5c3DhIreLLueiqBkn9K4LTNV8a32jnXLW3sbyyuLh54rOU+VNGm75QG+6eMdeaveNAJrGLRLFQt3rV4LZWHVIlwZH+gHH411NjpNlDZtaxwKsUZ8tV9FAAAr001SgpNJt9+y/zf5HjSUq1RxUmku3d/wCS/M53TPC2pazqVvrXjG6SR4nE1vp1uMQwt/CWJ5Yj/Jrtag+xW/8AzyWj7Fb/APPJa56lSVR6nTSpRpKy67vuFz96D/rqP5Gp6pXNnb7oP3S/60fyNTfYrf8A55LWZqT0VB9it/8AnktH2K3/AOeS0AFp/qn/AOur/wDoRqeqVpZ2/lP+6X/Wv/6Eam+xW/8AzyWgCeoJ/wDj4tv+uh/9Aaj7Fb/88lqGezt/Ptv3S/6w/wDoLUAWLpd1rKP9k1Dpq4swx6uxY1J9it/+eS0CxtgMCFQPQU76WJtrckESCYyhfnIwT7VHZ/8AHqP95v8A0I0fYrf/AJ5LUNnZ25th+6X7zf8AoRpFF2ioPsVv/wA8lo+xW/8AzyWgCU/65f8AdP8ASnVAlvFFcKY0CkqRkfUVPQAUUUUAFFFFABRRRQBR1NnLWlurtGtxPsdkba20IzYBHIztHI5qGzvltdPvZL2UiGylkXzZDk7FGeT3xnGevFXrm1iu4hHOGIDBgVYqVI6EEYIpLeygtVQQB1CbsZkY5LHJJyfmOe5yaAMXw9rKalquoL/aMFwdsciQRTK/kqQeOPwyfU/StPVLhFsZ0IkyF7RsR+eMVaS3ijuJZ0XEkoUO2Tzjp/OodS/5B03+7/WgB/2uL+7N/wB+X/wo+1xf3Zv+/L/4VPRQBB9ri/uzf9+X/wAKytNuYx4g1kkSYZ4cYib/AJ5j24rcrI0z/kYtb/66Q/8AooUAaH2uL+7N/wB+X/wo+1xf3Zv+/L/4VPRQBSu7uPyB8sv+sT/li/8AeHtQ96kx2RiXZ/Ewhf8ALpS6kcwRx5xvlQH6bhTNW1ODRNLe5lGQvyxxjq7HooqJNJNvY1hFyaUVdvY5rxDqFvdal/ZzSNBZRIsl7KUYbIwc46dziuj065hisxEqSqsZKgCF+Bn6VwOtadc3dhZaJPIV1HxNe+bdsuMpAg3ED6cY/Guk8AX88mlXWlak2dR0qc28+f4gB8j/AEYDr3wa6IYdqj7Z7vp2Wy/G/wAznq4pOusPH4Y9e8nq/wALW8kY3jWdNS1Gz0RRIRqOoRLMvltkwoFd+Mc9BWt4h0G31HWrbUtPvLzSdSCNGbu3gb51HOHUjDCqdjGdU+Md9Mfmi0i1Cj/ZllAH/oINdpPbJcbPMzhTnA710TqOkoRXb8/+BY4oU41nOUl1svl/wbnIeHvEmpW/iabQfEN1HesYBNaXcVq0ZlAOGBUdx14HrXQ6ncIyQlBLnzVH+pfufpXN+PraSwNjr9hH+/0dxOVUcvFnbIv/AHyc/ga6xp4ruytbiBg8UrRyRsO4OCD+VZV4qUVUj1/NG+GnKE5U5O9tvR/0yuJYpbt03XCrGigbI3HP5VJa3yKJYpDMxjbq0Tk47dqqarrtn4fsL7Ur9vkVwiIv3pXxgIo7k/8A165C+8ca7ounz3HiPQJLOa5tm+zS2/zx7yPkV+6sMgHPX0qqdCdRe6RUxNOk7yf9efYt+G5V1rx1qGsSiRrbTE+xWuI2I8wndK3A4I4X6GuytruP998sv+tb/li/+FUPBujf2D4TsrNx+/KebOT1MjfM2fXk4/CtW2/5bf8AXVqjESUqj5dlov6/EvDQcKa5t3q/n/lsH2uL+7N/35f/AAo+1xf3Zv8Avy/+FT0VgdJRubuPdB8sv+tH/LF/Q+1T/a4v7s3/AH5f/Ci5+9B/11H8jU9AEH2uL+7N/wB+X/wo+1xf3Zv+/L/4VPRQBStLuPyn+WX/AFr/APLF/wC8fapvtcX92b/vy/8AhRaf6p/+ur/+hGp6AIPtcX92b/vy/wDhUM93H59t8sv+sP8Ayxf+63tV2oJ/+Pi2/wCuh/8AQGoAPtcX92b/AL8v/hR9ri/uzf8Afl/8KnooAg+1xf3Zv+/L/wCFQWd3H9mHyy/eb/li/wDePtV6oLP/AI9R/vN/6EaAD7XF/dm/78v/AIUfa4v7s3/fl/8ACp6KAIEnSW4UKHB2k/NGy9x6ip6af9cv+6f6U6gAooooAKKKKACiiigAoqC6uktI1ZlZ2dgiRoPmdvQZ47HrxTY7+B7KS6bdGkW7zA45Qr1BA+nbOe1AFmqOqGf7DPsWMpt4JY5/lUlrfLcyvEYpYJUUOY5QMlTnDcEjsffjkUal/wAg6b/d/rQA/N1/ch/77P8AhRm6/uQ/99n/AAqeigCDN1/ch/77P+FZWmm4/wCEg1nCxZ3w5yx/55j2rcrI0z/kYtb/AOukP/ooUAaGbr+5D/32f8KM3X9yH/vs/wCFT0jMEUs3AFAGJqxuZWSMrEB5sanDH+8D6Vk2NveeItZF9MyS6fYuUtgzHEjDq/Tn2NTeJppJDaadC224v5MA/wBxSRlvwH86PEupPoWm2fh/w2gOq3o8m0X/AJ5L/FK3sOTn19eaiEZVqiprZav1/wCAtfuN6k44ai6st3ovTr970XzKmi+frfxD1bVgkTQ6Wg02Aljt353SEcdQePoaNX8N6xceKp9T0XVY9JeW3Ed2yp5hkUYIIBGAeCM9q6Tw7oVv4c0SHT7Ul9nzSSt96Vz95j7k0t8xS6ZV6zRhR9c/4V3e2/ee5ta3y/rU8pUE6SVTe936+v4GR4Q0KTRbe8dZWurm6mDz3FzKWdztGO3Tk/nXRZuv7kP/AH2f8KS1UI06josgA/74WrFc85ucnJnXThGnFRjsZeowyziOO4hgeKTdE6ljhlYYIPFcx4NuLyxt7rwxclGn0a6VELsQXhY7o26enHtxXZX4/wBEZh1Qhh+dcL8RbHUrS/stb8OjF1dJ/Z02PRzmN/bDd/pXRQSqL2Te+3qv6Zy4hunL2yV7b+j/AODZjtCt5vFniu61q5CS6fplw0NjEznY0o+/L057AH/CuzvLa4vIPKdIMZzyxP8ASoPDGlQ6J4astPt/uQx4Jx94k5LfiSTWrWdapzT93ZaI0oUuWn7271f9eWxADdAYCQ/99n/CobY3X775If8AWt/Gf8Ku1Bbf8tv+urVgdIZuv7kP/fZ/wozdf3If++z/AIVPRQBSuTdboPkh/wBaP4z6H2qbN1/ch/77P+FFz96D/rqP5Gp6AIM3X9yH/vs/4UZuv7kP/fZ/wqeigClaG68p/kh/1r/xn+8faps3X9yH/vs/4UWn+qf/AK6v/wChGp6AIM3X9yH/AL7P+FQzm68+2+SH/WH+M/3W9qu1BP8A8fFt/wBdD/6A1ABm6/uQ/wDfZ/wozdf3If8Avs/4VPRQBBm6/uQ/99n/AAqGzN19mHyQ/eb+M/3j7VdqCz/49R/vN/6EaADN1/ch/wC+z/hRm6/uQ/8AfZ/wqeigCBDMbhfNWMDafusT3HtU9NP+uX/dP9KdQAUUUUAFFFFABRRRQBS1KKVmtZ4IjMbefeY1IBYFWU4yQON2evaoLJLu3t7l1tWE1xJJMqO64Q8BVYg9TjtkDnmtSigDK0y2lTUbm5NvPBHMiZW5lEjbsnOCGbCjPTOM5wOcmfVIN1jO/mSDK9A3FXqo6ncQrYzo00YcLypYZoAn+yj/AJ7Tf990fZR/z2m/77pftlt/z8Rf99ij7Zbf8/EX/fYoAT7KP+e03/fdZOm2+fEGsjzZRh4eQ/X92K1/tlt/z8Rf99isnTbmAeINZYzxgM8OCXHP7sUAav2Uf89pv++6hNr505UzTbE6/P1NTNe2yqSbiLgZ++KwtZ1UraxWGnzx/bb9iDJuGIU/icntx0rOpNQV2b0KbqSsv+G7v5Ix5bu1W71jxHfTyCy08pBA27lsMN2PcngfWrfg/RLm5ebxNrhlTUtQX91Hv5toOqp9T1P+OaxdZSzkuvDnhu2eNrY3f2y5+Yf6uM4Ab/eYmvRftlt/z8Rf99iuqMXRopfalq/69fyRxVJrEYhyXww0X+f3P72xPso/57Tf991DLpokuYpTPN8nbf1qf7Zbf8/EX/fYo+2W3/PxF/32KyTsatXILe1Hm3H76b/W/wB//ZWpvso/57Tf991Db3dt5tx/pEX+t/vj+6tT/bLb/n4i/wC+xSGRzWXmQuvnTfMpH36z7mINoyN50xIKqQX6HOK1Ptlt/wA/EX/fYrH1S5gizGs8ZSeVCMOODuGauOuhE9NTUhtAtvGPOm4Ufx+1P+yj/ntN/wB90v2u2/5+Iv8AvsUfbLb/AJ+Iv++xUFifZR/z2m/77qG2tR+9/fTf61v46n+2W3/PxF/32Kgtru2/ff6RF/rW/jFAE32Uf89pv++6Pso/57Tf990v2y2/5+Iv++xR9stv+fiL/vsUAV7m1G6D99N/rR/H7Gp/so/57Tf991Dc3dtug/0iL/Wj+Mehqf7Zbf8APxF/32KAE+yj/ntN/wB90fZR/wA9pv8Avul+2W3/AD8Rf99ij7Zbf8/EX/fYoAgtLUeU/wC+m/1r/wAf+0am+yj/AJ7Tf991DaXdt5T/AOkRf61/4x/eNT/bLb/n4i/77FACfZR/z2m/77qGe1Hn2376b/WH+P8A2Wqf7Zbf8/EX/fYqCe7tvPtv9Ii/1h/jH91qAJvso/57Tf8AfdH2Uf8APab/AL7pftlt/wA/EX/fYo+2W3/PxF/32KAE+yj/AJ7Tf991BZ2o+zD99N95v4/9o1Y+2W3/AD8Rf99ioLO7tvsw/wBIi+838Y/vGgCb7KP+e03/AH3R9lH/AD2m/wC+6X7Zbf8APxF/32KPtlt/z8Rf99igBEh8u4U+ZI3ykYZs9xU9QpPDLcKIpUc7ScKwPcVNQAUUUUAFFFFABRRRQAUVn6sBI1lBLzDNcbZVPRhsYgH2JA471Fp0fmWN9bb3ihWeSKJo2wUX/ZPbBJA9Me1AGrVXUgP7Om4/h/rVXSIYhNPc2UYis5QojVeA5GcyY98jnvjPpU2qSyCynUQMy7fvBlwf1oAu7R6D8qNo9B+VQ+fL/wA+sn/fS/40efL/AM+sn/fS/wCNAE20eg/KsjTAP+Ei1rgf6yH/ANFCtHz5f+fWT/vpf8ayLC4ePXdac27n54SRuXj92PegDTv5ooLdjKQiKCzt/dUck1haNDJdLLqs6bbjUm2wKesUA6D8Rz+VQXtxN4huZNPt4m+yxuDfTBh0Bz5anOO3NQ+JNfvLZYbDRrYjVtRBgsUyuIUH3pSAeAB0/risqEHiK11svz/4H+Z04mosJh+V/FLfvbt6t/p3IvDqLqnibXtbAzDDPFptqcfwRspcj1BYg13O0eg/KsDSdKXw74bttMtbeV1hZN0jMuZGLgsx57k1s+fL/wA+sn/fS/4111pqc247bL5Hn4eDhTSlvu/Vk20eg/KjaPQflUPny/8APrJ/30v+NHny/wDPrJ/30v8AjWJuJbqPNueB/rfT/ZWp9o9B+VU7eaXzbj/RZP8AW/3l/ur71N58v/PrJ/30v+NAE20eg/Kqt/CsscOQPlnRhx71J58v/PrJ/wB9L/jUF1NLtj/0WT/Wr/Evr9aA3Lu0eg/KjaPQflUPny/8+sn/AH0v+NHny/8APrJ/30v+NAE20eg/KoLZR++4H+tbtS+fL/z6yf8AfS/41DbTS/vv9Fk/1rfxL/jQBc2j0H5UbR6D8qh8+X/n1k/76X/Gjz5f+fWT/vpf8aAEuVG6Dgf60dvY1PtHoPyqlczS7oP9Fk/1o/iX0PvU/ny/8+sn/fS/40ATbR6D8qNo9B+VQ+fL/wA+sn/fS/40efL/AM+sn/fS/wCNACWijyn4H+tft/tGp9o9B+VU7SaXyn/0WT/Wv/Ev94+9TefL/wA+sn/fS/40ATbR6D8qgnUfaLbgf6w9v9hqXz5f+fWT/vpf8ahnml8+2/0WT/WH+Jf7re9AFzaPQflRtHoPyqHz5f8An1k/76X/ABo8+X/n1k/76X/GgCbaPQflUFmo+yjgfebt/tGl8+X/AJ9ZP++l/wAags5pfsw/0WT7zfxL/ePvQBd2j0H5UbR6D8qh8+X/AJ9ZP++l/wAaPPl/59ZP++l/xoAkwBMuB/Cf6U+oEkd7hQ8LRjaeSQe49DU9ABRRRQAUUUUAFFFFAEc8ENzEYriJJYzjKOoYHHI4NR/YLMQrELSDy1RkCeWMBW6rj0Pcd6sUUAV7XTrKyJNlZ29uWGCYolTI/AU3Uv8AkHTf7v8AWrVUtQile1lxNhCANu0fzoAu0VX8i5/5+z/37FHkXP8Az9n/AL9igCxXF3891N4m1LSdNys93JEXl7RRiNct+vFdZ5Fz/wA/Z/79iueu/B8Gpa1cXzajf291lVMlrO0WQFHYHFTKHtFyt2RpTq+ylzqPM1sulyrruuaf4TsIdG0yL7VfSYWKzi5kmY9zjpnqT+VXPCvhq5sJpdY1+YXOtXSBXYfct4+oiT2Hf1/Uz6N4Qs9CnmuLKRmupzmW6nHmSv8AVm5/AVseRc/8/Z/79iupzhCn7OktO/8AWyOJU6lWr7au7vov182Ld/8AHuP+uif+hip6oXUNwIBm6J/eJ/yzH94VP5Fz/wA/Z/79iuc6SxRVfyLn/n7P/fsUeRc/8/Z/79igBbf/AFtz/wBdf/ZVqeqEENwZbjF0RiTn92OflWp/Iuf+fs/9+xQBYqC6+7H/ANdU/nSeRc/8/Z/79ioLmG4Cx5uif3i/8sx60AX6Kr+Rc/8AP2f+/Yo8i5/5+z/37FAFioLb/lt/11ak8i5/5+z/AN+xUFtDcHzcXRH7w5/djmgC/RVfyLn/AJ+z/wB+xR5Fz/z9n/v2KAFufvQf9dR/I1PVC4huA0GbonMgx+7HHBqfyLn/AJ+z/wB+xQBYoqv5Fz/z9n/v2KPIuf8An7P/AH7FAC2n+qf/AK6v/wChGp6oWsNwYmxdEfvH/wCWY/vGp/Iuf+fs/wDfsUAWKgn/AOPi2/66H/0BqTyLn/n7P/fsVBNDcCe3zdE5kOP3Y4+VqAL9FV/Iuf8An7P/AH7FHkXP/P2f+/YoAsVBZ/8AHqP95v8A0I0nkXP/AD9n/v2KgtIbg24xdEDc3Hlj+8aAL9FV/Iuf+fs/9+xR5Fz/AM/Z/wC/YoAmP+uX/dP9KdVeOOVLgeZOZBtOBtAxyKsUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFUrbVIbqZURJFWQFoZGA2ygdSvOe/fGeoyKukZBFYlhaXQl06Ke2eJbCNlMhZSshxtG0Ak4I55AoA26KKKAKt7fCz8oCCW4klYqkcW3JwCSeSB0HrU8TmSFXaNoiwyUfGV9jgkVT1KEStAz2LXiqWyEkCsmR1wSAR+PHH4S6ZFPDpkEd0WMqrhtzbiPQE9yBgZ70AWqr319Dp9sZ7gSFBnPlxM+OM84HA9zxViquqQyXGk3cMK7pJIXVRnGSRxQA261KK1faY5ZSqebJ5ag+Wn948+x4GScHirasHUMpyrDII7ism+huo7q4e3tXuBcWohGxlGxgW67iODv7Z6GtK0g+zWUEGd3lRqmfXAxQBLVWDUYLh51jEim3+/5kTJ69NwGRweelWqo/Zpftl+5jDJNEioGbAYgNkccjqKAH2F+b+PzBaXECMoZGm2/OD6YYn88VbrJ0u2livGdLWWzt/IVDFJIGy4PUYY9BwT1PHpWtQBWur1baRI1ilnlcFhHEBnaMZPJA7jvUDa1ahFkjWWWLylleRF4iRujNnB7HgAkY5o1aW9WOOKxtppRK2JZImQNGvtuYcnoPTr7HPubO5NreW1tp8ixXtssSDeg8g4K4b5ugBB4z3/FgdBQTgZPSkUbVA9BilpAZ6a1bsjO0c0cfktPG7qMSouMlefccHB5qezu3u1LPaT2wGMedt+b6bWNZiLd3v2p7/Spg8kbxxxySxhAn93KsTlsDJxxwO2Ta0yCWO7uJPs8trbuiBIZXDHeM7mGGIHVR15IJ9ywNKqt1frbSLGIZZ5CpcpEASqjqTkgd+nU9gatVnasks0fkfZbiaF0OWtZ/LdW7DO5eD9frSAX+2rYlWjEkkJCFp0X5E34255zzkdAcZ5xWhXODT79bCaxktt5uhEWmiKKkeFVW4yDxsyMDuK6OgBHdY42dztVQSSewqgNZgEMsksU0XlwmcK6gGSMfxAZ/Q4PPSr0m8Rt5YBfB2hjwT2rD+xzzz3M7afPtmtyssFxcA72z91GDHaMZ9ByvvgA17W5e5RjJaTWxBwBNtyf++WNT1naZBLFcXTmGS3gcr5cMjhiCB8xGCQAeOPUE960aAKuo6jb6VZPdXbMI1wMKuST6AUyXVIYbloikhVGVJJVA2Rs2NoPOecjoDjPOKzfEmk6lqMEzWFxb/8AHu0ccEsBY7j1IbeoBIwORxz60s9lfMtzaPAZftU8UpuYyqouAm7ILFh9w4HPUc9cMDeooopAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAH//2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5juIkr256V_"
      },
      "source": [
        "## CNN and LSTM Models Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS6EaZ7HqFrz"
      },
      "source": [
        "Now we will make an ensemble of all the cnn models trained on spetrogram RGB image and lstm model trained on yamnet embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuF5g4mk6tMM"
      },
      "source": [
        "## EfficientNetB3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXonIgKe5-pv",
        "outputId": "dbc15575-de51-464e-ea64-9bae95961201"
      },
      "source": [
        "backbone_2 = tf.keras.applications.EfficientNetB3(include_top = False,input_shape = (img_ht,img_wt,3), weights=\"imagenet\")\n",
        "\n",
        "for layer in backbone_2.layers[:0]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_2 = tf.keras.Sequential([\n",
        "            backbone_2,\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "            tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.he_normal()),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            #tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Dense(class_n,bias_initializer=tf.keras.initializers.Constant(-2.))])\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "43941888/43941136 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnetb3 (Functional)  (None, 12, 24, 1536)      10783535  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               196736    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 10,983,367\n",
            "Trainable params: 10,896,064\n",
            "Non-trainable params: 87,303\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrljYWHJ6xbb"
      },
      "source": [
        "### DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngfmWkXz6qpl",
        "outputId": "aa906e08-6619-4557-d5ec-271ec7d3db63"
      },
      "source": [
        "backbone_3 = tf.keras.applications.DenseNet121(include_top = False,input_shape = (img_ht,img_wt,3), weights=\"imagenet\")\n",
        "\n",
        "for layer in backbone_3.layers[:0]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_3 = tf.keras.Sequential([\n",
        "            backbone_3,\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "            tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.he_normal()),\n",
        "            tf.keras.layers.Dropout(0.3),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Dense(class_n,bias_initializer=tf.keras.initializers.Constant(-2.))])\n",
        "\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Functional)     (None, 12, 24, 1024)      7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 7,172,312\n",
            "Trainable params: 7,088,408\n",
            "Non-trainable params: 83,904\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBYz8nkkWXPC"
      },
      "source": [
        "###LSTM Model with yamnet embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSVz8svBWM4j",
        "outputId": "6ae1a32d-8a97-4258-e17e-9b5211424ea0"
      },
      "source": [
        "#Train a NN classifier with embedding features\n",
        "def lstm_model():\n",
        "\n",
        "  input_layer= tf.keras.layers.Input(shape=(124,1024), name='Input_layer')\n",
        "  lstm_layer= tf.keras.layers.LSTM(512,return_sequences=True)(inputs=input_layer)\n",
        "  td=tf.keras.layers.GlobalAveragePooling1D()(lstm_layer)\n",
        "  dense_2= tf.keras.layers.Dense(324, activation='relu',kernel_initializer='he_normal')(td)\n",
        "  drop_out1= tf.keras.layers.Dropout(0.7)(dense_2)\n",
        "  dense_3= tf.keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal')(drop_out1)\n",
        "  drop_out2= tf.keras.layers.Dropout(0.5)(dense_3)\n",
        "  dense_4=tf.keras.layers.Dense(64, activation='relu',kernel_initializer='he_normal')(drop_out2)\n",
        "  dense_5=tf.keras.layers.Dense(32, activation='relu',kernel_initializer='he_normal')(dense_4)\n",
        "  output= tf.keras.layers.Dense(class_n, activation='sigmoid')(dense_5)\n",
        "  model= tf.keras.models.Model(inputs=[input_layer], outputs=[output])\n",
        "\n",
        "  opt=tf.keras.optimizers.Adam()  # Optimizer\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy',metrics=[lwlrap])\n",
        "\n",
        "  return model\n",
        "  \n",
        "model_4=lstm_model()\n",
        "model_4.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_layer (InputLayer)     [(None, 124, 1024)]       0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 124, 512)          3147776   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 324)               166212    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 324)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               41600     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 24)                792       \n",
            "=================================================================\n",
            "Total params: 3,366,716\n",
            "Trainable params: 3,366,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDz5TWxdIxe6"
      },
      "source": [
        "### Saving all the architectures in json files to use later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dcbZ0Q8IwzV",
        "outputId": "ad7442f5-a4ff-4080-a174-62abd86cf5b2"
      },
      "source": [
        "#Serialize models to JSON\n",
        "\n",
        "model_1_json=model_1.to_json()\n",
        "model_2_json=model_2.to_json()\n",
        "model_3_json=model_3.to_json()\n",
        "model_4_json=model_4.to_json()\n",
        "\n",
        "with open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_1.json','w') as json_file_1:\n",
        "  json_file_1.write(model_1_json)\n",
        "\n",
        "with open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_2.json','w') as json_file_2:\n",
        "  json_file_2.write(model_2_json)\n",
        "\n",
        "with open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_3.json','w') as json_file_3:\n",
        "  json_file_3.write(model_3_json)\n",
        "\n",
        "with open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_4.json','w') as json_file_4:\n",
        "  json_file_4.write(model_4_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2aMZa-W68b0"
      },
      "source": [
        "### Loading the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGR3IyOK6_2k"
      },
      "source": [
        "model_1.load_weights('/content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_6/weights-26-0.6329.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgO11Uvg7R6C"
      },
      "source": [
        "model_2.load_weights('/content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_1/21-0.9206-0.7486.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EO1oan97qMI"
      },
      "source": [
        "model_3.load_weights('/content/drive/MyDrive/Appliedai files/Case_Study_2/CS2_modelling2/model_2/32-0.8647-0.7383.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN6aDcaSW6dw"
      },
      "source": [
        "model_4.load_weights('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_1/weights-69-0.6032.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKolhJ_DSg3G"
      },
      "source": [
        "yamnet_model_handle= 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet_model=hub.load(yamnet_model_handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5LVF2W0Sg-Y"
      },
      "source": [
        "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
        "def load_flac_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    #audio,sr=librosa.load(filename,mono=True,sr=16000)\n",
        "    audio = tfio.IOTensor.graph(tf.int16).from_audio(filename)\n",
        "    audio_slice = audio.to_tensor()\n",
        "\n",
        "    # remove last dimension\n",
        "    audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
        "    audio_tensor = tf.cast(audio_tensor, tf.float32)\n",
        "    sample_rate = tf.cast(48000, dtype=tf.int64)\n",
        "    audio_tensor = tfio.audio.resample(audio_tensor, rate_in=sample_rate, rate_out=16000)\n",
        "\n",
        "    scores, embeddings, spectrogram = yamnet_model(audio_tensor)\n",
        "    return embeddings\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIGqJd6pShHl"
      },
      "source": [
        "def preprocess_embed_train(file):\n",
        "    \"\"\"Preprocessing train files\"\"\"\n",
        "    # Calling the preprocess_img function with data_type as train\n",
        "    \n",
        "    audio = load_flac_16k_mono('/content/drive/MyDrive/Appliedai files/Case_Study_2/train/'+file['recording_id']+'.flac')\n",
        "    \n",
        "    # Computing the one hot encoded values of species_id\n",
        "    label = tf.one_hot(file['species_id'], CLASS_N)\n",
        "    # Returning the spectrogram and one hot encoded species_id\n",
        "    return audio,label\n",
        "\n",
        "\n",
        "def preprocess_embed_val(file):\n",
        "    \"\"\"Preprocessing validation files\"\"\"\n",
        "    # Calling the preprocess_img function with data_type as validation\n",
        "    audio = load_flac_16k_mono('/content/drive/MyDrive/Appliedai files/Case_Study_2/train/'+file['recording_id']+'.flac')\n",
        "\n",
        "    # Computing the one hot encoded values of species_id\n",
        "    label = tf.one_hot(file['species_id'], CLASS_N)\n",
        "    # Returning the spectrogram and one hot encoded species_id\n",
        "    return audio, label\n",
        "\n",
        "    \n",
        "def preprocess_embed_test(file):\n",
        "    \"\"\"Preprocessing test files\"\"\"\n",
        "    # Calling the preprocess_img function with data_type as test\n",
        "    audio = load_flac_16k_mono('/content/drive/MyDrive/Appliedai files/Case_Study_2/test/'+file)\n",
        "\n",
        "    file_name = tf.strings.split(file,'.')[0]\n",
        "    # Returning only the spectrogram image for test dataset \n",
        "    return audio,file_name\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKBmNfeAShMX",
        "outputId": "6327c40a-7c70-44df-a645-ad2b9c3df12f"
      },
      "source": [
        "#Dataset for LSTM yamnet model\n",
        "# Creating a dataset from train data and mapping the preprocess train function \n",
        "files_ds_tr = tf.data.Dataset.from_tensor_slices(dict(X_train))\n",
        "train_embed_dataset = files_ds_tr.map(preprocess_embed_train).cache().prefetch(-1)\n",
        "\n",
        "# Creating a dataset from train data and mapping the preprocess train function \n",
        "files_ds_val = tf.data.Dataset.from_tensor_slices(dict(X_cv))\n",
        "val_embed_dataset = files_ds_val.map(preprocess_embed_val).cache().prefetch(-1)\n",
        "\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(test)\n",
        "test_embed_dataset = files_ds.map(preprocess_embed_test).cache().prefetch(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/parallel_for/pfor.py:2382: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/parallel_for/pfor.py:2382: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfJFlTRY_rqG"
      },
      "source": [
        "#dataset for cnn models\n",
        "\n",
        "# Creating a dataset from train data and mapping the preprocess train function \n",
        "files_ds = tf.data.Dataset.from_tensor_slices(dict(X_train))\n",
        "train_dataset = files_ds.map(preprocess_train).cache().prefetch(-1)\n",
        "\n",
        "# Creating a dataset from train data and mapping the preprocess train function \n",
        "files_ds = tf.data.Dataset.from_tensor_slices(dict(X_cv))\n",
        "val_dataset = files_ds.map(preprocess_val).cache().prefetch(-1)\n",
        "\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(test)\n",
        "test_dataset = files_ds.map(preprocess_test).cache().prefetch(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI9tGXJ-AXRW"
      },
      "source": [
        "cnn_models=[model_1,model_2,model_3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDyK3k_rQxil"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def ensemble_predictions(cnn_models,cnn_dataset,rnn_model,rnn_dataset):\n",
        "\n",
        "  cnn_final_pred=[]\n",
        "  rnn_final_pred=[]\n",
        "  final_pred=[]\n",
        "  cnn_id = []\n",
        "  rnn_id= []\n",
        "\n",
        "  for image,file in tqdm(cnn_dataset.batch(1)):\n",
        "    cnn_id.append(file)\n",
        "    y_pred = []\n",
        "    for model in cnn_models:\n",
        "      #taking the sigmoid of predictions\n",
        "      pred = tf.sigmoid(model(image)).numpy()\n",
        "      y_pred.append(pred)\n",
        "    y_pred=np.asarray(y_pred)\n",
        "    #Taking the mean of predictions\n",
        "    mean_pred=np.mean(y_pred,axis=0)\n",
        "    cnn_final_pred.append(mean_pred)\n",
        "  #predictions from lstm model\n",
        "  for embed,file in tqdm(rnn_dataset.batch(1)):\n",
        "    rnn_id.append(file)\n",
        "    rnn_pred=rnn_model.predict(embed)\n",
        "    rnn_final_pred.append(rnn_pred)\n",
        "  \n",
        "\n",
        "  #combining CNN and lstm predictions and taking mean\n",
        "  for i,j in zip(cnn_final_pred,rnn_final_pred):\n",
        "    pred_list=[]\n",
        "    pred_list.append(i)\n",
        "    pred_list.append(j)\n",
        "    pred_list=np.asarray(pred_list)\n",
        "    mean_final_pred=np.mean(pred_list,axis=0)\n",
        "    final_pred.append(mean_final_pred)\n",
        "\n",
        "  return final_pred,cnn_id,rnn_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAKk0fQbdTal",
        "outputId": "548fa8d8-2554-4ba1-c918-2233a388f8b5"
      },
      "source": [
        "ensemble_train_pred,cnn_label,rnn_label=ensemble_predictions(cnn_models,train_dataset,model_4,train_embed_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1094/1094 [26:35<00:00,  1.46s/it]\n",
            "100%|██████████| 1094/1094 [00:46<00:00, 23.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyy2aDavC-Pk",
        "outputId": "2bed73b7-4e75-4a57-8e48-b2b9d7737d5f"
      },
      "source": [
        "ensemble_val_pred,cnn_val_label,rnn_val_label=ensemble_predictions(cnn_models,val_dataset,model_4,val_embed_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 122/122 [00:05<00:00, 22.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ri79etrhZ6"
      },
      "source": [
        "####Predictions on train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjrACiAwv-zk",
        "outputId": "14ecce23-4a86-4224-fd1a-30e106e4ecf5"
      },
      "source": [
        "train_pred=np.asarray(ensemble_train_pred,dtype='float16')\n",
        "train_pred=train_pred.reshape(1094,24)\n",
        "\n",
        "y_train=[]\n",
        "for i in rnn_label:\n",
        "  k=i.numpy()\n",
        "  y_train.append(k)\n",
        "\n",
        "y_train=np.asarray(y_train)\n",
        "y_train=y_train.reshape(1094,24)\n",
        "\n",
        "train_lwlrap=lwlrap(y_train,train_pred)\n",
        "\n",
        "print(train_lwlrap)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.9219465482719601, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vAWyCxrmE0"
      },
      "source": [
        "#### Predictions on Validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VK3h9wwwz-n",
        "outputId": "3e13bc89-3e46-430c-bf5a-a78bbe798ab8"
      },
      "source": [
        "val_pred=np.asarray(ensemble_val_pred,dtype='float16')\n",
        "val_pred=val_pred.reshape(122,24)\n",
        "\n",
        "y_val=[]\n",
        "for a in rnn_val_label:\n",
        "  b=a.numpy()\n",
        "  y_val.append(a)\n",
        "\n",
        "y_val=np.asarray(y_val)\n",
        "y_val=y_val.reshape(122,24)\n",
        "\n",
        "val_lwlrap=lwlrap(y_val,val_pred)\n",
        "\n",
        "print(val_lwlrap)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.9387978142076502, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwVfPVZ1rquE"
      },
      "source": [
        "#### Predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3K_YNvDARS",
        "outputId": "5e151559-7766-453d-d477-d09f6b4befd9"
      },
      "source": [
        "ensemble_test_pred,test_cnn_id,test_rnn_id=ensemble_predictions(cnn_models,test_dataset,model_4,test_embed_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1992/1992 [1:16:29<00:00,  2.30s/it]\n",
            "100%|██████████| 1992/1992 [26:04<00:00,  1.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_80-V7qREO_"
      },
      "source": [
        "test_pred=np.asarray(ensemble_test_pred,dtype='float16')\n",
        "test_pred=test_pred.reshape(1992,24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xAsK7o6REWT"
      },
      "source": [
        "column_names=[]\n",
        "\n",
        "for i in range(24):\n",
        "  column_names.append('s'+str(i))\n",
        "\n",
        "df_index=[i for i in range(1992)]\n",
        "\n",
        "test_recording_id=[]\n",
        "for i in test_cnn_id:\n",
        "  k=i.numpy()\n",
        "  k=str(k)\n",
        "  test_recording_id.append(k[3:-2])\n",
        "\n",
        "\n",
        "results_df=pd.DataFrame(data=test_pred,index=df_index,columns=column_names)\n",
        "\n",
        "results_df['recording_id']=test_recording_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "cA4iJDcoREdq",
        "outputId": "cccdc99b-4cb9-40f1-be6e-c8581c6aeb56"
      },
      "source": [
        "new_results=results_df.reindex(columns=['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18',\n",
        "                            's19','s20','s21','s22','s23'])\n",
        "\n",
        "new_results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recording_id</th>\n",
              "      <th>s0</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>s22</th>\n",
              "      <th>s23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7c712b45f</td>\n",
              "      <td>0.020950</td>\n",
              "      <td>0.019745</td>\n",
              "      <td>0.045044</td>\n",
              "      <td>0.130615</td>\n",
              "      <td>0.019867</td>\n",
              "      <td>0.059845</td>\n",
              "      <td>0.041656</td>\n",
              "      <td>0.121643</td>\n",
              "      <td>0.022766</td>\n",
              "      <td>0.059692</td>\n",
              "      <td>0.103210</td>\n",
              "      <td>0.051575</td>\n",
              "      <td>0.022217</td>\n",
              "      <td>0.008789</td>\n",
              "      <td>0.017929</td>\n",
              "      <td>0.061035</td>\n",
              "      <td>0.029968</td>\n",
              "      <td>0.184326</td>\n",
              "      <td>0.016876</td>\n",
              "      <td>0.160034</td>\n",
              "      <td>0.111267</td>\n",
              "      <td>0.036407</td>\n",
              "      <td>0.110413</td>\n",
              "      <td>0.205078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7d064b789</td>\n",
              "      <td>0.580566</td>\n",
              "      <td>0.017273</td>\n",
              "      <td>0.022385</td>\n",
              "      <td>0.037415</td>\n",
              "      <td>0.024078</td>\n",
              "      <td>0.022461</td>\n",
              "      <td>0.015388</td>\n",
              "      <td>0.013199</td>\n",
              "      <td>0.033112</td>\n",
              "      <td>0.018295</td>\n",
              "      <td>0.010406</td>\n",
              "      <td>0.018234</td>\n",
              "      <td>0.540527</td>\n",
              "      <td>0.024139</td>\n",
              "      <td>0.010475</td>\n",
              "      <td>0.018387</td>\n",
              "      <td>0.021347</td>\n",
              "      <td>0.026672</td>\n",
              "      <td>0.070618</td>\n",
              "      <td>0.014130</td>\n",
              "      <td>0.009529</td>\n",
              "      <td>0.015404</td>\n",
              "      <td>0.012573</td>\n",
              "      <td>0.009727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7cfaed5a0</td>\n",
              "      <td>0.368896</td>\n",
              "      <td>0.040527</td>\n",
              "      <td>0.021652</td>\n",
              "      <td>0.076477</td>\n",
              "      <td>0.055756</td>\n",
              "      <td>0.042267</td>\n",
              "      <td>0.025284</td>\n",
              "      <td>0.031799</td>\n",
              "      <td>0.068542</td>\n",
              "      <td>0.048004</td>\n",
              "      <td>0.021408</td>\n",
              "      <td>0.026871</td>\n",
              "      <td>0.628418</td>\n",
              "      <td>0.022491</td>\n",
              "      <td>0.026764</td>\n",
              "      <td>0.026840</td>\n",
              "      <td>0.032928</td>\n",
              "      <td>0.031311</td>\n",
              "      <td>0.160645</td>\n",
              "      <td>0.015839</td>\n",
              "      <td>0.030930</td>\n",
              "      <td>0.034943</td>\n",
              "      <td>0.035187</td>\n",
              "      <td>0.030182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7d188d367</td>\n",
              "      <td>0.156860</td>\n",
              "      <td>0.022995</td>\n",
              "      <td>0.026627</td>\n",
              "      <td>0.084473</td>\n",
              "      <td>0.093323</td>\n",
              "      <td>0.034973</td>\n",
              "      <td>0.028503</td>\n",
              "      <td>0.034332</td>\n",
              "      <td>0.062744</td>\n",
              "      <td>0.053802</td>\n",
              "      <td>0.011795</td>\n",
              "      <td>0.044769</td>\n",
              "      <td>0.358643</td>\n",
              "      <td>0.021683</td>\n",
              "      <td>0.021347</td>\n",
              "      <td>0.021225</td>\n",
              "      <td>0.018967</td>\n",
              "      <td>0.018768</td>\n",
              "      <td>0.356934</td>\n",
              "      <td>0.020782</td>\n",
              "      <td>0.032928</td>\n",
              "      <td>0.036591</td>\n",
              "      <td>0.022888</td>\n",
              "      <td>0.025757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7df2eb324</td>\n",
              "      <td>0.011520</td>\n",
              "      <td>0.016373</td>\n",
              "      <td>0.016357</td>\n",
              "      <td>0.059418</td>\n",
              "      <td>0.021469</td>\n",
              "      <td>0.028305</td>\n",
              "      <td>0.141235</td>\n",
              "      <td>0.031281</td>\n",
              "      <td>0.023315</td>\n",
              "      <td>0.178833</td>\n",
              "      <td>0.045929</td>\n",
              "      <td>0.046661</td>\n",
              "      <td>0.033295</td>\n",
              "      <td>0.010803</td>\n",
              "      <td>0.015556</td>\n",
              "      <td>0.024429</td>\n",
              "      <td>0.021820</td>\n",
              "      <td>0.314453</td>\n",
              "      <td>0.014832</td>\n",
              "      <td>0.049652</td>\n",
              "      <td>0.057404</td>\n",
              "      <td>0.029495</td>\n",
              "      <td>0.025238</td>\n",
              "      <td>0.390625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  recording_id        s0        s1  ...       s21       s22       s23\n",
              "0    7c712b45f  0.020950  0.019745  ...  0.036407  0.110413  0.205078\n",
              "1    7d064b789  0.580566  0.017273  ...  0.015404  0.012573  0.009727\n",
              "2    7cfaed5a0  0.368896  0.040527  ...  0.034943  0.035187  0.030182\n",
              "3    7d188d367  0.156860  0.022995  ...  0.036591  0.022888  0.025757\n",
              "4    7df2eb324  0.011520  0.016373  ...  0.029495  0.025238  0.390625\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3lyO1RHRsgD"
      },
      "source": [
        "new_results.to_csv('/content/drive/MyDrive/Appliedai files/Case_Study_2/submission_8.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr1-1FlrCyDZ"
      },
      "source": [
        "Converting models to TFLite format for deployement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms9reUs_Bx8t",
        "outputId": "cb5e56b7-6d4a-4b6b-86fe-c4110cc25372"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_1)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model_1 = converter.convert()\n",
        "open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_1.tflite' , 'wb') .write(tflite_quant_model_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp4apmohk7/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9332848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsuNy2tsCOYl",
        "outputId": "18ce7a75-7eaa-4c35-f50c-c652769d4210"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model_2 = converter.convert()\n",
        "open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_2.tflite' , 'wb') .write(tflite_quant_model_2)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_3)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model_3 = converter.convert()\n",
        "open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_3.tflite' , 'wb') .write(tflite_quant_model_3)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_4)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model_4 = converter.convert()\n",
        "open ('/content/drive/MyDrive/Appliedai files/Case_Study_2/model_4.tflite' , 'wb') .write(tflite_quant_model_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpyoqm510a/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpyoqm510a/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplgg5fm1y/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplgg5fm1y/assets\n",
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input_layer with unsupported characters which will be renamed to input_layer in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpap4fzgyl/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpap4fzgyl/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3651088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjywGf3Z2Akv"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB4qsMP7fAVd",
        "outputId": "7646089e-e402-4f86-dee9-94793f462e4b"
      },
      "source": [
        "!pip install prettytable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable) (4.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqgH1lwZfH_F",
        "outputId": "cac2fbc9-b893-460a-b9e1-0343673cc6ae"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "summary = PrettyTable()\n",
        "summary.field_names = [\"Model\", \"lrap\"]\n",
        "summary.add_row([\"EfficientNetB2\",0.632])\n",
        "summary.add_row([\"EfficientNetB3\", 0.748])\n",
        "summary.add_row([\"DenseNet121\", 0.738])\n",
        "summary.add_row([\"LSTM\", 0.603])\n",
        "summary.add_row([\"Ensemble Model\", 0.938])\n",
        "print(summary)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-------+\n",
            "|     Model      |  lrap |\n",
            "+----------------+-------+\n",
            "| EfficientNetB2 | 0.632 |\n",
            "| EfficientNetB3 | 0.748 |\n",
            "|  DenseNet121   | 0.738 |\n",
            "|      LSTM      | 0.603 |\n",
            "| Ensemble Model | 0.938 |\n",
            "+----------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}